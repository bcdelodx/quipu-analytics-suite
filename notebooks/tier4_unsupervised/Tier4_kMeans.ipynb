{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tier 4: K-Means Clustering\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** Brandon Deloatch\n",
    "**Affiliation:** Quipu Research Labs, LLC\n",
    "**Date:** 2025-10-02\n",
    "**Version:** v1.3\n",
    "**License:** MIT\n",
    "**Notebook ID:** 3f3d3bb9-6068-4d6e-82de-72776edb6955\n",
    "\n",
    "---\n",
    "\n",
    "## Citation\n",
    "Brandon Deloatch, \"Tier 4: K-Means Clustering,\" Quipu Research Labs, LLC, v1.3, 2025-10-02.\n",
    "\n",
    "Please cite this notebook if used or adapted in publications, presentations, or derivative work.\n",
    "\n",
    "---\n",
    "\n",
    "## Contributors / Acknowledgments\n",
    "- **Primary Author:** Brandon Deloatch (Quipu Research Labs, LLC)\n",
    "- **Institutional Support:** Quipu Research Labs, LLC - Advanced Analytics Division\n",
    "- **Technical Framework:** Built on scikit-learn, pandas, numpy, and plotly ecosystems\n",
    "- **Methodological Foundation:** Statistical learning principles and modern data science best practices\n",
    "\n",
    "---\n",
    "\n",
    "## Version History\n",
    "| Version | Date | Notes |\n",
    "|---------|------|-------|\n",
    "| v1.3 | 2025-10-02 | Enhanced professional formatting, comprehensive documentation, interactive visualizations |\n",
    "| v1.2 | 2024-09-15 | Updated analysis methods, improved data generation algorithms |\n",
    "| v1.0 | 2024-06-10 | Initial release with core analytical framework |\n",
    "\n",
    "---\n",
    "\n",
    "## Environment Dependencies\n",
    "- **Python:** 3.8+\n",
    "- **Core Libraries:** pandas 2.0+, numpy 1.24+, scikit-learn 1.3+\n",
    "- **Visualization:** plotly 5.0+, matplotlib 3.7+\n",
    "- **Statistical:** scipy 1.10+, statsmodels 0.14+\n",
    "- **Development:** jupyter-lab 4.0+, ipywidgets 8.0+\n",
    "\n",
    "> **Reproducibility Note:** Use requirements.txt or environment.yml for exact dependency matching.\n",
    "\n",
    "---\n",
    "\n",
    "## Data Provenance\n",
    "| Dataset | Source | License | Notes |\n",
    "|---------|--------|---------|-------|\n",
    "| Synthetic Data | Generated in-notebook | MIT | Custom algorithms for realistic simulation |\n",
    "| Statistical Distributions | NumPy/SciPy | BSD-3-Clause | Standard library implementations |\n",
    "| ML Algorithms | Scikit-learn | BSD-3-Clause | Industry-standard implementations |\n",
    "| Visualization Schemas | Plotly | MIT | Interactive dashboard frameworks |\n",
    "\n",
    "---\n",
    "\n",
    "## Execution Provenance Logs\n",
    "- **Created:** 2025-10-02\n",
    "- **Notebook ID:** 3f3d3bb9-6068-4d6e-82de-72776edb6955\n",
    "- **Execution Environment:** Jupyter Lab / VS Code\n",
    "- **Computational Requirements:** Standard laptop/workstation (2GB+ RAM recommended)\n",
    "\n",
    "> **Auto-tracking:** Execution metadata can be programmatically captured for reproducibility.\n",
    "\n",
    "---\n",
    "\n",
    "## Disclaimer & Responsible Use\n",
    "This notebook is provided \"as-is\" for educational, research, and professional development purposes. Users assume full responsibility for any results, applications, or decisions derived from this analysis.\n",
    "\n",
    "**Professional Standards:**\n",
    "- Validate all results against domain expertise and additional data sources\n",
    "- Respect licensing and attribution requirements for all dependencies\n",
    "- Follow ethical guidelines for data analysis and algorithmic decision-making\n",
    "- Credit all methodological sources and derivative frameworks appropriately\n",
    "\n",
    "**Academic & Commercial Use:**\n",
    "- Permitted under MIT license with proper attribution\n",
    "- Suitable for educational curriculum and professional training\n",
    "- Appropriate for commercial adaptation with citation requirements\n",
    "- Recommended for reproducible research and transparent analytics\n",
    "\n",
    "---\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9b738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\" Tier 4: K-Means Clustering - Libraries Loaded!\")\n",
    "print(\"=\" * 50)\n",
    "print(\"K-Means Techniques:\")\n",
    "print(\"• Standard K-Means with Lloyd's algorithm\")\n",
    "print(\"• K-Means++ smart initialization\")\n",
    "print(\"• Mini-Batch K-Means for large datasets\")\n",
    "print(\"• Elbow method for optimal K selection\")\n",
    "print(\"• Silhouette analysis for cluster validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeb47da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate K-Means optimized datasets\n",
    "np.random.seed(42)\n",
    "\n",
    "# Customer segmentation data\n",
    "n_customers = 1000\n",
    "customer_data = pd.DataFrame({\n",
    " 'annual_spending': np.random.gamma(2, 15000, n_customers),\n",
    " 'visit_frequency': np.random.poisson(8, n_customers),\n",
    " 'avg_transaction': np.random.lognormal(4, 0.5, n_customers),\n",
    " 'loyalty_years': np.random.exponential(2, n_customers)\n",
    "})\n",
    "\n",
    "# Create synthetic clusters for validation\n",
    "centers = [(30000, 12, 80, 3), (15000, 4, 40, 1), (50000, 20, 150, 5)]\n",
    "true_clusters = make_blobs(n_samples=n_customers, centers=centers, n_features=4,\n",
    " cluster_std=5000, random_state=42)[1]\n",
    "\n",
    "print(\" K-Means Datasets Created:\")\n",
    "print(f\"Customer data: {len(customer_data)} samples with {customer_data.shape[1]} features\")\n",
    "print(f\"Spending range: ${customer_data['annual_spending'].min():,.0f} - ${customer_data['annual_spending'].max():,.0f}\")\n",
    "print(f\"Transaction range: ${customer_data['avg_transaction'].min():.0f} - ${customer_data['avg_transaction'].max():.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f773b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. K-MEANS CLUSTERING WITH VISUALIZATION\n",
    "print(\" 1. K-MEANS CLUSTERING ANALYSIS\")\n",
    "print(\"=\" * 33)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "customer_scaled = scaler.fit_transform(customer_data)\n",
    "\n",
    "# Apply K-Means with different K values\n",
    "k_range = range(2, 11)\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "kmeans_models = {}\n",
    "\n",
    "for k in k_range:\n",
    " kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42, n_init=10)\n",
    " clusters = kmeans.fit_predict(customer_scaled)\n",
    "\n",
    " inertias.append(kmeans.inertia_)\n",
    " silhouette_scores.append(silhouette_score(customer_scaled, clusters))\n",
    " kmeans_models[k] = kmeans\n",
    "\n",
    " print(f\"K={k}: Inertia={kmeans.inertia_:.0f}, Silhouette={silhouette_score(customer_scaled, clusters):.3f}\")\n",
    "\n",
    "# Find optimal K using elbow method\n",
    "elbow_k = 3 # Typically determined by visual inspection\n",
    "optimal_kmeans = kmeans_models[elbow_k]\n",
    "customer_clusters = optimal_kmeans.fit_predict(customer_scaled)\n",
    "\n",
    "print(f\"\\nOptimal K selected: {elbow_k}\")\n",
    "print(f\"Final silhouette score: {silhouette_score(customer_scaled, customer_clusters):.3f}\")\n",
    "\n",
    "# Cluster analysis\n",
    "customer_data['cluster'] = customer_clusters\n",
    "cluster_summary = customer_data.groupby('cluster').agg({\n",
    " 'annual_spending': ['mean', 'std'],\n",
    " 'visit_frequency': ['mean', 'std'],\n",
    " 'avg_transaction': ['mean', 'std'],\n",
    " 'loyalty_years': ['mean', 'std']\n",
    "}).round(2)\n",
    "\n",
    "print(f\"\\nCluster Summary:\")\n",
    "for cluster in range(elbow_k):\n",
    " cluster_size = sum(customer_clusters == cluster)\n",
    " spending_avg = customer_data[customer_data['cluster'] == cluster]['annual_spending'].mean()\n",
    " print(f\"Cluster {cluster}: {cluster_size} customers, avg spending ${spending_avg:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d587ef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. INTERACTIVE VISUALIZATIONS\n",
    "print(\" 2. INTERACTIVE K-MEANS VISUALIZATIONS\")\n",
    "print(\"=\" * 39)\n",
    "\n",
    "# Create comprehensive visualization dashboard\n",
    "fig = make_subplots(\n",
    " rows=2, cols=2,\n",
    " subplot_titles=[\n",
    " 'Elbow Method for Optimal K',\n",
    " 'Silhouette Analysis',\n",
    " 'Customer Clusters (Spending vs Frequency)',\n",
    " 'Cluster Centers Comparison'\n",
    " ],\n",
    " specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    " [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
    ")\n",
    "\n",
    "# Elbow method plot\n",
    "fig.add_trace(\n",
    " go.Scatter(x=list(k_range), y=inertias, mode='lines+markers',\n",
    " name='Inertia', line=dict(color='blue', width=3),\n",
    " marker=dict(size=8)),\n",
    " row=1, col=1\n",
    ")\n",
    "\n",
    "# Silhouette scores\n",
    "fig.add_trace(\n",
    " go.Scatter(x=list(k_range), y=silhouette_scores, mode='lines+markers',\n",
    " name='Silhouette Score', line=dict(color='green', width=3),\n",
    " marker=dict(size=8)),\n",
    " row=1, col=2\n",
    ")\n",
    "\n",
    "# Customer clusters scatter plot\n",
    "colors = ['red', 'blue', 'green', 'purple', 'orange']\n",
    "for cluster in range(elbow_k):\n",
    " cluster_data = customer_data[customer_data['cluster'] == cluster]\n",
    " fig.add_trace(\n",
    " go.Scatter(x=cluster_data['annual_spending'],\n",
    " y=cluster_data['visit_frequency'],\n",
    " mode='markers',\n",
    " name=f'Cluster {cluster}',\n",
    " marker=dict(color=colors[cluster], size=6, opacity=0.7)),\n",
    " row=2, col=1\n",
    " )\n",
    "\n",
    "# Add cluster centers\n",
    "centers_original = scaler.inverse_transform(optimal_kmeans.cluster_centers_)\n",
    "for i, center in enumerate(centers_original):\n",
    " fig.add_trace(\n",
    " go.Scatter(x=[center[0]], y=[center[1]], mode='markers',\n",
    " marker=dict(color='black', size=15, symbol='x'),\n",
    " name=f'Center {i}', showlegend=False),\n",
    " row=2, col=1\n",
    " )\n",
    "\n",
    "# Cluster centers radar chart\n",
    "features = ['Annual Spending', 'Visit Frequency', 'Avg Transaction', 'Loyalty Years']\n",
    "for i, center in enumerate(centers_original):\n",
    " # Normalize for radar chart\n",
    " normalized_center = (center - customer_data.iloc[:, :4].min()) / (customer_data.iloc[:, :4].max() - customer_data.iloc[:, :4].min())\n",
    " fig.add_trace(\n",
    " go.Scatter(x=features, y=normalized_center, mode='lines+markers',\n",
    " name=f'Cluster {i} Profile', line=dict(color=colors[i])),\n",
    " row=2, col=2\n",
    " )\n",
    "\n",
    "fig.update_layout(height=800, title=\"K-Means Clustering Analysis Dashboard\", showlegend=True)\n",
    "fig.update_xaxes(title_text=\"Number of Clusters (K)\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Number of Clusters (K)\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"Annual Spending ($)\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Features\", row=2, col=2)\n",
    "fig.update_yaxes(title_text=\"Inertia\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Silhouette Score\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Visit Frequency\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Normalized Values\", row=2, col=2)\n",
    "fig.show()\n",
    "\n",
    "# Business insights\n",
    "print(f\"\\n BUSINESS INSIGHTS:\")\n",
    "for cluster in range(elbow_k):\n",
    " cluster_data = customer_data[customer_data['cluster'] == cluster]\n",
    " cluster_size = len(cluster_data)\n",
    "\n",
    " avg_spending = cluster_data['annual_spending'].mean()\n",
    " avg_frequency = cluster_data['visit_frequency'].mean()\n",
    " avg_transaction = cluster_data['avg_transaction'].mean()\n",
    " avg_loyalty = cluster_data['loyalty_years'].mean()\n",
    "\n",
    " # Determine customer segment type\n",
    " if avg_spending > 40000 and avg_frequency > 15:\n",
    " segment_type = \"VIP Customers\"\n",
    " elif avg_spending > 25000:\n",
    " segment_type = \"High-Value Customers\"\n",
    " elif avg_frequency > 10:\n",
    " segment_type = \"Frequent Shoppers\"\n",
    " else:\n",
    " segment_type = \"Casual Customers\"\n",
    "\n",
    " total_revenue = cluster_size * avg_spending\n",
    "\n",
    " print(f\"\\nCluster {cluster}: {segment_type}\")\n",
    " print(f\"• Size: {cluster_size} customers ({cluster_size/len(customer_data)*100:.1f}%)\")\n",
    " print(f\"• Annual spending: ${avg_spending:,.0f}\")\n",
    " print(f\"• Visit frequency: {avg_frequency:.1f} times/year\")\n",
    " print(f\"• Avg transaction: ${avg_transaction:.0f}\")\n",
    " print(f\"• Customer loyalty: {avg_loyalty:.1f} years\")\n",
    " print(f\"• Total cluster revenue: ${total_revenue:,.0f}\")\n",
    "\n",
    "# ROI calculation\n",
    "total_revenue = customer_data['annual_spending'].sum()\n",
    "targeting_efficiency = 0.25 # 25% improvement in marketing efficiency\n",
    "marketing_roi = total_revenue * targeting_efficiency * 0.1 # 10% of revenue as marketing impact\n",
    "\n",
    "print(f\"\\n K-MEANS CLUSTERING ROI:\")\n",
    "print(f\"• Total customer revenue: ${total_revenue:,.0f}\")\n",
    "print(f\"• Marketing efficiency improvement: {targeting_efficiency*100:.0f}%\")\n",
    "print(f\"• Estimated annual ROI: ${marketing_roi:,.0f}\")\n",
    "print(f\"• Implementation cost: $75,000\")\n",
    "print(f\"• Net ROI: {(marketing_roi - 75000)/75000*100:.0f}%\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}