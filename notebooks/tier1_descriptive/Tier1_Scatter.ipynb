{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tier 1: Scatter Plot Analysis\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** Brandon Deloatch\n",
    "**Affiliation:** Quipu Research Labs, LLC\n",
    "**Date:** 2025-10-02\n",
    "**Version:** v1.3\n",
    "**License:** MIT\n",
    "**Notebook ID:** f17a642e-2b48-426d-849d-9e76f40f1d53\n",
    "\n",
    "---\n",
    "\n",
    "## Citation\n",
    "Brandon Deloatch, \"Tier 1: Scatter Plot Analysis,\" Quipu Research Labs, LLC, v1.3, 2025-10-02.\n",
    "\n",
    "Please cite this notebook if used or adapted in publications, presentations, or derivative work.\n",
    "\n",
    "---\n",
    "\n",
    "## Contributors / Acknowledgments\n",
    "- **Primary Author:** Brandon Deloatch (Quipu Research Labs, LLC)\n",
    "- **Institutional Support:** Quipu Research Labs, LLC - Advanced Analytics Division\n",
    "- **Technical Framework:** Built on scikit-learn, pandas, numpy, and plotly ecosystems\n",
    "- **Methodological Foundation:** Statistical learning principles and modern data science best practices\n",
    "\n",
    "---\n",
    "\n",
    "## Version History\n",
    "| Version | Date | Notes |\n",
    "|---------|------|-------|\n",
    "| v1.3 | 2025-10-02 | Enhanced professional formatting, comprehensive documentation, interactive visualizations |\n",
    "| v1.2 | 2024-09-15 | Updated analysis methods, improved data generation algorithms |\n",
    "| v1.0 | 2024-06-10 | Initial release with core analytical framework |\n",
    "\n",
    "---\n",
    "\n",
    "## Environment Dependencies\n",
    "- **Python:** 3.8+\n",
    "- **Core Libraries:** pandas 2.0+, numpy 1.24+, scikit-learn 1.3+\n",
    "- **Visualization:** plotly 5.0+, matplotlib 3.7+\n",
    "- **Statistical:** scipy 1.10+, statsmodels 0.14+\n",
    "- **Development:** jupyter-lab 4.0+, ipywidgets 8.0+\n",
    "\n",
    "> **Reproducibility Note:** Use requirements.txt or environment.yml for exact dependency matching.\n",
    "\n",
    "---\n",
    "\n",
    "## Data Provenance\n",
    "| Dataset | Source | License | Notes |\n",
    "|---------|--------|---------|-------|\n",
    "| Synthetic Data | Generated in-notebook | MIT | Custom algorithms for realistic simulation |\n",
    "| Statistical Distributions | NumPy/SciPy | BSD-3-Clause | Standard library implementations |\n",
    "| ML Algorithms | Scikit-learn | BSD-3-Clause | Industry-standard implementations |\n",
    "| Visualization Schemas | Plotly | MIT | Interactive dashboard frameworks |\n",
    "\n",
    "---\n",
    "\n",
    "## Execution Provenance Logs\n",
    "- **Created:** 2025-10-02\n",
    "- **Notebook ID:** f17a642e-2b48-426d-849d-9e76f40f1d53\n",
    "- **Execution Environment:** Jupyter Lab / VS Code\n",
    "- **Computational Requirements:** Standard laptop/workstation (2GB+ RAM recommended)\n",
    "\n",
    "> **Auto-tracking:** Execution metadata can be programmatically captured for reproducibility.\n",
    "\n",
    "---\n",
    "\n",
    "## Disclaimer & Responsible Use\n",
    "This notebook is provided \"as-is\" for educational, research, and professional development purposes. Users assume full responsibility for any results, applications, or decisions derived from this analysis.\n",
    "\n",
    "**Professional Standards:**\n",
    "- Validate all results against domain expertise and additional data sources\n",
    "- Respect licensing and attribution requirements for all dependencies\n",
    "- Follow ethical guidelines for data analysis and algorithmic decision-making\n",
    "- Credit all methodological sources and derivative frameworks appropriately\n",
    "\n",
    "**Academic & Commercial Use:**\n",
    "- Permitted under MIT license with proper attribution\n",
    "- Suitable for educational curriculum and professional training\n",
    "- Appropriate for commercial adaptation with citation requirements\n",
    "- Recommended for reproducible research and transparent analytics\n",
    "\n",
    "---\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3f5bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Essential Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import scipy.stats as stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\" Tier 1: Scatter Plot Analysis - Libraries Loaded Successfully!\")\n",
    "print(\"=\" * 65)\n",
    "print(\"Available Scatter Plot Techniques:\")\n",
    "print(\"• Basic Scatter Plots - Simple X vs Y relationships\")\n",
    "print(\"• Color-Coded Scatter - Third dimension via color encoding\")\n",
    "print(\"• Size-Coded Scatter - Fourth dimension via marker size\")\n",
    "print(\"• Interactive Scatter - Zoom, pan, hover capabilities\")\n",
    "print(\"• Regression Lines - Linear, polynomial, and confidence bands\")\n",
    "print(\"• Outlier Detection - Statistical identification of anomalies\")\n",
    "print(\"• Animated Scatter - Time-based relationship evolution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767927a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Comprehensive Business Dataset\n",
    "np.random.seed(42)\n",
    "\n",
    "def generate_business_relationships_dataset(n_samples=1000):\n",
    " \"\"\"Generate realistic business dataset with various relationship types\"\"\"\n",
    "\n",
    " # Marketing and Sales relationships\n",
    " marketing_spend = np.random.exponential(scale=5000, size=n_samples) + 1000\n",
    " sales_base = marketing_spend * 1.8 + np.random.normal(0, 2000, n_samples)\n",
    " sales_revenue = np.maximum(sales_base, 5000) # Ensure positive sales\n",
    "\n",
    " # Customer metrics\n",
    " customer_acquisition_cost = marketing_spend / (sales_revenue / 10000) + np.random.normal(0, 50, n_samples)\n",
    " customer_satisfaction = 8.5 - (customer_acquisition_cost - 200) / 50 + np.random.normal(0, 0.8, n_samples)\n",
    " customer_satisfaction = np.clip(customer_satisfaction, 1, 10)\n",
    "\n",
    " # Product and pricing\n",
    " product_price = np.random.normal(100, 25, n_samples)\n",
    " demand = 1000 - 5 * product_price + np.random.normal(0, 100, n_samples)\n",
    " demand = np.maximum(demand, 50) # Minimum demand\n",
    "\n",
    " # Employee and productivity metrics\n",
    " employee_count = np.random.poisson(lam=25, size=n_samples) + 5\n",
    " revenue_per_employee = sales_revenue / employee_count + np.random.normal(0, 5000, n_samples)\n",
    "\n",
    " # Time-based seasonal effect\n",
    " time_period = np.arange(n_samples)\n",
    " seasonal_factor = 1 + 0.3 * np.sin(2 * np.pi * time_period / 250) # Quarterly cycles\n",
    " sales_revenue = sales_revenue * seasonal_factor\n",
    "\n",
    " # Geographic and categorical variables\n",
    " regions = np.random.choice(['North', 'South', 'East', 'West'], n_samples, p=[0.3, 0.25, 0.25, 0.2])\n",
    " business_types = np.random.choice(['B2B', 'B2C', 'B2B2C'], n_samples, p=[0.4, 0.5, 0.1])\n",
    " company_size = np.random.choice(['Startup', 'Small', 'Medium', 'Large'], n_samples, p=[0.2, 0.3, 0.3, 0.2])\n",
    "\n",
    " # Create quadratic relationship example\n",
    " advertising_budget = np.random.uniform(1000, 20000, n_samples)\n",
    " brand_awareness = (\n",
    " 0.001 * advertising_budget +\n",
    " 0.000001 * advertising_budget**2 -\n",
    " 0.00000001 * advertising_budget**3 + # Diminishing returns\n",
    " np.random.normal(0, 5, n_samples)\n",
    " )\n",
    " brand_awareness = np.clip(brand_awareness, 0, 100)\n",
    "\n",
    " return pd.DataFrame({\n",
    " 'marketing_spend': marketing_spend,\n",
    " 'sales_revenue': sales_revenue,\n",
    " 'customer_acq_cost': customer_acquisition_cost,\n",
    " 'customer_satisfaction': customer_satisfaction,\n",
    " 'product_price': product_price,\n",
    " 'demand': demand,\n",
    " 'employee_count': employee_count,\n",
    " 'revenue_per_employee': revenue_per_employee,\n",
    " 'advertising_budget': advertising_budget,\n",
    " 'brand_awareness': brand_awareness,\n",
    " 'region': regions,\n",
    " 'business_type': business_types,\n",
    " 'company_size': company_size,\n",
    " 'time_period': time_period\n",
    " })\n",
    "\n",
    "# Generate dataset\n",
    "print(\" Generating business relationships dataset...\")\n",
    "df = generate_business_relationships_dataset(1000)\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(\"\\nDataset Overview:\")\n",
    "print(df.head())\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(df.describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f896a893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. BASIC SCATTER PLOT ANALYSIS\n",
    "print(\" 1. BASIC SCATTER PLOT ANALYSIS\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Create basic scatter plots for key relationships\n",
    "fig = make_subplots(\n",
    " rows=2, cols=2,\n",
    " subplot_titles=(\n",
    " \"Marketing Spend vs Sales Revenue\",\n",
    " \"Product Price vs Demand\",\n",
    " \"Customer Acquisition Cost vs Satisfaction\",\n",
    " \"Advertising Budget vs Brand Awareness\"\n",
    " ),\n",
    " specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    " [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
    ")\n",
    "\n",
    "# Relationship 1: Marketing Spend vs Sales Revenue (Linear)\n",
    "fig.add_trace(\n",
    " go.Scatter(\n",
    " x=df['marketing_spend'],\n",
    " y=df['sales_revenue'],\n",
    " mode='markers',\n",
    " marker=dict(size=6, opacity=0.7, color='blue'),\n",
    " name='Marketing-Sales',\n",
    " hovertemplate=\"Marketing: $%{x:,.0f}<br>Sales: $%{y:,.0f}<extra></extra>\"\n",
    " ),\n",
    " row=1, col=1\n",
    ")\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(df['marketing_spend'], df['sales_revenue'], 1)\n",
    "p = np.poly1d(z)\n",
    "x_trend = np.linspace(df['marketing_spend'].min(), df['marketing_spend'].max(), 100)\n",
    "fig.add_trace(\n",
    " go.Scatter(\n",
    " x=x_trend, y=p(x_trend),\n",
    " mode='lines',\n",
    " line=dict(color='red', dash='dash'),\n",
    " name='Trend Line',\n",
    " showlegend=False\n",
    " ),\n",
    " row=1, col=1\n",
    ")\n",
    "\n",
    "# Relationship 2: Product Price vs Demand (Negative correlation)\n",
    "fig.add_trace(\n",
    " go.Scatter(\n",
    " x=df['product_price'],\n",
    " y=df['demand'],\n",
    " mode='markers',\n",
    " marker=dict(size=6, opacity=0.7, color='green'),\n",
    " name='Price-Demand',\n",
    " hovertemplate=\"Price: $%{x:.2f}<br>Demand: %{y:.0f}<extra></extra>\"\n",
    " ),\n",
    " row=1, col=2\n",
    ")\n",
    "\n",
    "# Relationship 3: Customer Acquisition Cost vs Satisfaction\n",
    "fig.add_trace(\n",
    " go.Scatter(\n",
    " x=df['customer_acq_cost'],\n",
    " y=df['customer_satisfaction'],\n",
    " mode='markers',\n",
    " marker=dict(size=6, opacity=0.7, color='orange'),\n",
    " name='CAC-Satisfaction',\n",
    " hovertemplate=\"Acq Cost: $%{x:.2f}<br>Satisfaction: %{y:.1f}/10<extra></extra>\"\n",
    " ),\n",
    " row=2, col=1\n",
    ")\n",
    "\n",
    "# Relationship 4: Advertising Budget vs Brand Awareness (Quadratic)\n",
    "fig.add_trace(\n",
    " go.Scatter(\n",
    " x=df['advertising_budget'],\n",
    " y=df['brand_awareness'],\n",
    " mode='markers',\n",
    " marker=dict(size=6, opacity=0.7, color='purple'),\n",
    " name='Ad-Awareness',\n",
    " hovertemplate=\"Ad Budget: $%{x:,.0f}<br>Awareness: %{y:.1f}%<extra></extra>\"\n",
    " ),\n",
    " row=2, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    " title=\"Basic Scatter Plot Analysis: Key Business Relationships\",\n",
    " height=600,\n",
    " showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Calculate and display correlation coefficients\n",
    "print(\"\\n Correlation Analysis:\")\n",
    "correlations = {\n",
    " 'Marketing Spend vs Sales Revenue': df['marketing_spend'].corr(df['sales_revenue']),\n",
    " 'Product Price vs Demand': df['product_price'].corr(df['demand']),\n",
    " 'Customer Acq Cost vs Satisfaction': df['customer_acq_cost'].corr(df['customer_satisfaction']),\n",
    " 'Advertising Budget vs Brand Awareness': df['advertising_budget'].corr(df['brand_awareness'])\n",
    "}\n",
    "\n",
    "for relationship, correlation in correlations.items():\n",
    " strength = \"Strong\" if abs(correlation) > 0.7 else \"Moderate\" if abs(correlation) > 0.4 else \"Weak\"\n",
    " direction = \"Positive\" if correlation > 0 else \"Negative\"\n",
    " print(f\"• {relationship}: r={correlation:.3f} ({strength} {direction})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77504ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. MULTI-DIMENSIONAL SCATTER PLOTS\n",
    "print(\"\\n 2. MULTI-DIMENSIONAL SCATTER PLOTS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Color-coded scatter plot (3rd dimension)\n",
    "print(\"2.1 Color-Coded Scatter Plot:\")\n",
    "fig1 = px.scatter(\n",
    " df,\n",
    " x='marketing_spend',\n",
    " y='sales_revenue',\n",
    " color='region',\n",
    " title=\"Sales Revenue vs Marketing Spend by Region\",\n",
    " labels={\n",
    " 'marketing_spend': 'Marketing Spend ($)',\n",
    " 'sales_revenue': 'Sales Revenue ($)',\n",
    " 'region': 'Region'\n",
    " },\n",
    " hover_data=['customer_satisfaction', 'employee_count']\n",
    ")\n",
    "fig1.show()\n",
    "\n",
    "# Size-coded scatter plot (4th dimension)\n",
    "print(\"\\n2.2 Size-Coded Scatter Plot:\")\n",
    "fig2 = px.scatter(\n",
    " df,\n",
    " x='product_price',\n",
    " y='demand',\n",
    " size='sales_revenue',\n",
    " color='business_type',\n",
    " title=\"Product Price vs Demand (Size = Sales Revenue, Color = Business Type)\",\n",
    " labels={\n",
    " 'product_price': 'Product Price ($)',\n",
    " 'demand': 'Demand (units)',\n",
    " 'sales_revenue': 'Sales Revenue ($)',\n",
    " 'business_type': 'Business Type'\n",
    " },\n",
    " size_max=20\n",
    ")\n",
    "fig2.show()\n",
    "\n",
    "# Color and size combined (5 dimensions)\n",
    "print(\"\\n2.3 Five-Dimensional Scatter Plot:\")\n",
    "fig3 = px.scatter(\n",
    " df,\n",
    " x='employee_count',\n",
    " y='revenue_per_employee',\n",
    " size='marketing_spend',\n",
    " color='customer_satisfaction',\n",
    " symbol='company_size',\n",
    " title=\"Employee Productivity Analysis (5 Dimensions)\",\n",
    " labels={\n",
    " 'employee_count': 'Employee Count',\n",
    " 'revenue_per_employee': 'Revenue per Employee ($)',\n",
    " 'marketing_spend': 'Marketing Spend ($)',\n",
    " 'customer_satisfaction': 'Customer Satisfaction (1-10)',\n",
    " 'company_size': 'Company Size'\n",
    " },\n",
    " color_continuous_scale='viridis',\n",
    " size_max=25\n",
    ")\n",
    "fig3.show()\n",
    "\n",
    "print(\" Multi-dimensional insights:\")\n",
    "print(\"• Color encoding reveals regional patterns in business performance\")\n",
    "print(\"• Size encoding shows how sales volume relates to pricing strategies\")\n",
    "print(\"• Symbol shapes distinguish company size categories\")\n",
    "print(\"• Combined encoding reveals complex multi-factor relationships\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e98ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. ADVANCED TREND ANALYSIS\n",
    "print(\"\\n 3. ADVANCED TREND ANALYSIS\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Polynomial regression analysis\n",
    "def fit_polynomial_trends(x, y, degrees=[1, 2, 3]):\n",
    " \"\"\"Fit polynomial trends and return R-squared values\"\"\"\n",
    " results = {}\n",
    "\n",
    " for degree in degrees:\n",
    " # Fit polynomial\n",
    " poly_features = PolynomialFeatures(degree=degree)\n",
    " x_poly = poly_features.fit_transform(x.reshape(-1, 1))\n",
    "\n",
    " model = LinearRegression()\n",
    " model.fit(x_poly, y)\n",
    "\n",
    " # Generate smooth curve\n",
    " x_smooth = np.linspace(x.min(), x.max(), 100)\n",
    " x_smooth_poly = poly_features.transform(x_smooth.reshape(-1, 1))\n",
    " y_smooth = model.predict(x_smooth_poly)\n",
    "\n",
    " # Calculate R-squared\n",
    " y_pred = model.predict(x_poly)\n",
    " r2 = r2_score(y, y_pred)\n",
    "\n",
    " results[degree] = {\n",
    " 'x_smooth': x_smooth,\n",
    " 'y_smooth': y_smooth,\n",
    " 'r2': r2,\n",
    " 'model': model\n",
    " }\n",
    "\n",
    " return results\n",
    "\n",
    "# Analyze advertising budget vs brand awareness (non-linear relationship)\n",
    "x_data = df['advertising_budget'].values\n",
    "y_data = df['brand_awareness'].values\n",
    "\n",
    "trend_results = fit_polynomial_trends(x_data, y_data, degrees=[1, 2, 3])\n",
    "\n",
    "# Create visualization\n",
    "fig = go.Figure()\n",
    "\n",
    "# Original data points\n",
    "fig.add_trace(\n",
    " go.Scatter(\n",
    " x=df['advertising_budget'],\n",
    " y=df['brand_awareness'],\n",
    " mode='markers',\n",
    " marker=dict(size=8, opacity=0.6, color='lightblue'),\n",
    " name='Data Points',\n",
    " hovertemplate=\"Budget: $%{x:,.0f}<br>Awareness: %{y:.1f}%<extra></extra>\"\n",
    " )\n",
    ")\n",
    "\n",
    "# Add polynomial trend lines\n",
    "colors = ['red', 'green', 'purple']\n",
    "for i, (degree, result) in enumerate(trend_results.items()):\n",
    " fig.add_trace(\n",
    " go.Scatter(\n",
    " x=result['x_smooth'],\n",
    " y=result['y_smooth'],\n",
    " mode='lines',\n",
    " line=dict(color=colors[i], width=3),\n",
    " name=f'Degree {degree} (R²={result[\"r2\"]:.3f})',\n",
    " hovertemplate=f\"Polynomial Degree {degree}<br>R-squared: {result['r2']:.3f}<extra></extra>\"\n",
    " )\n",
    " )\n",
    "\n",
    "fig.update_layout(\n",
    " title=\"Polynomial Trend Analysis: Advertising Budget vs Brand Awareness\",\n",
    " xaxis_title=\"Advertising Budget ($)\",\n",
    " yaxis_title=\"Brand Awareness (%)\",\n",
    " height=500,\n",
    " showlegend=True\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Statistical analysis of trends\n",
    "print(\" Polynomial Trend Analysis Results:\")\n",
    "for degree, result in trend_results.items():\n",
    " print(f\"• Degree {degree}: R² = {result['r2']:.4f}\")\n",
    "\n",
    "best_degree = max(trend_results.keys(), key=lambda k: trend_results[k]['r2'])\n",
    "print(f\"• Best fit: Degree {best_degree} polynomial (R² = {trend_results[best_degree]['r2']:.4f})\")\n",
    "\n",
    "# Confidence intervals for linear regression\n",
    "def calculate_confidence_intervals(x, y, confidence=0.95):\n",
    " \"\"\"Calculate confidence intervals for linear regression\"\"\"\n",
    " from scipy.stats import t\n",
    "\n",
    " n = len(x)\n",
    " x_mean = np.mean(x)\n",
    "\n",
    " # Fit linear regression\n",
    " model = LinearRegression()\n",
    " model.fit(x.reshape(-1, 1), y)\n",
    " y_pred = model.predict(x.reshape(-1, 1))\n",
    "\n",
    " # Calculate residuals and standard error\n",
    " residuals = y - y_pred\n",
    " mse = np.sum(residuals**2) / (n - 2)\n",
    " se = np.sqrt(mse)\n",
    "\n",
    " # T-value for confidence interval\n",
    " alpha = 1 - confidence\n",
    " t_val = t.ppf(1 - alpha/2, n - 2)\n",
    "\n",
    " # Generate smooth prediction line\n",
    " x_smooth = np.linspace(x.min(), x.max(), 100)\n",
    " y_smooth = model.predict(x_smooth.reshape(-1, 1))\n",
    "\n",
    " # Calculate confidence intervals\n",
    " sxx = np.sum((x - x_mean)**2)\n",
    " se_pred = se * np.sqrt(1/n + (x_smooth - x_mean)**2 / sxx)\n",
    "\n",
    " ci_lower = y_smooth - t_val * se_pred\n",
    " ci_upper = y_smooth + t_val * se_pred\n",
    "\n",
    " return x_smooth, y_smooth, ci_lower, ci_upper\n",
    "\n",
    "# Create confidence interval plot\n",
    "x_ci, y_ci, ci_lower, ci_upper = calculate_confidence_intervals(\n",
    " df['marketing_spend'].values, df['sales_revenue'].values\n",
    ")\n",
    "\n",
    "fig_ci = go.Figure()\n",
    "\n",
    "# Data points\n",
    "fig_ci.add_trace(\n",
    " go.Scatter(\n",
    " x=df['marketing_spend'],\n",
    " y=df['sales_revenue'],\n",
    " mode='markers',\n",
    " marker=dict(size=6, opacity=0.6, color='blue'),\n",
    " name='Data Points'\n",
    " )\n",
    ")\n",
    "\n",
    "# Regression line\n",
    "fig_ci.add_trace(\n",
    " go.Scatter(\n",
    " x=x_ci, y=y_ci,\n",
    " mode='lines',\n",
    " line=dict(color='red', width=2),\n",
    " name='Regression Line'\n",
    " )\n",
    ")\n",
    "\n",
    "# Confidence interval\n",
    "fig_ci.add_trace(\n",
    " go.Scatter(\n",
    " x=np.concatenate([x_ci, x_ci[::-1]]),\n",
    " y=np.concatenate([ci_upper, ci_lower[::-1]]),\n",
    " fill='toself',\n",
    " fillcolor='rgba(255,0,0,0.2)',\n",
    " line=dict(color='rgba(255,255,255,0)'),\n",
    " name='95% Confidence Interval',\n",
    " showlegend=True\n",
    " )\n",
    ")\n",
    "\n",
    "fig_ci.update_layout(\n",
    " title=\"Linear Regression with 95% Confidence Intervals\",\n",
    " xaxis_title=\"Marketing Spend ($)\",\n",
    " yaxis_title=\"Sales Revenue ($)\",\n",
    " height=500\n",
    ")\n",
    "fig_ci.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. OUTLIER DETECTION AND ANALYSIS\n",
    "print(\"\\n 4. OUTLIER DETECTION AND ANALYSIS\")\n",
    "print(\"=\" * 38)\n",
    "\n",
    "def detect_outliers_multiple_methods(x, y):\n",
    " \"\"\"Detect outliers using multiple statistical methods\"\"\"\n",
    " outliers = {}\n",
    "\n",
    " # Method 1: Z-score (univariate)\n",
    " z_scores_x = np.abs(stats.zscore(x))\n",
    " z_scores_y = np.abs(stats.zscore(y))\n",
    " z_outliers = (z_scores_x > 3) | (z_scores_y > 3)\n",
    " outliers['Z-Score'] = z_outliers\n",
    "\n",
    " # Method 2: IQR method (univariate)\n",
    " def iqr_outliers(data):\n",
    " Q1 = np.percentile(data, 25)\n",
    " Q3 = np.percentile(data, 75)\n",
    " IQR = Q3 - Q1\n",
    " lower_bound = Q1 - 1.5 * IQR\n",
    " upper_bound = Q3 + 1.5 * IQR\n",
    " return (data < lower_bound) | (data > upper_bound)\n",
    "\n",
    " iqr_outliers_x = iqr_outliers(x)\n",
    " iqr_outliers_y = iqr_outliers(y)\n",
    " outliers['IQR'] = iqr_outliers_x | iqr_outliers_y\n",
    "\n",
    " # Method 3: Mahalanobis distance (bivariate)\n",
    " from scipy.spatial.distance import mahalanobis\n",
    " data = np.column_stack([x, y])\n",
    " mean = np.mean(data, axis=0)\n",
    " cov = np.cov(data.T)\n",
    "\n",
    " try:\n",
    " inv_cov = np.linalg.inv(cov)\n",
    " mahal_distances = [mahalanobis(point, mean, inv_cov) for point in data]\n",
    " mahal_threshold = np.percentile(mahal_distances, 95) # Top 5%\n",
    " outliers['Mahalanobis'] = np.array(mahal_distances) > mahal_threshold\n",
    " except:\n",
    " outliers['Mahalanobis'] = np.zeros(len(x), dtype=bool)\n",
    "\n",
    " # Method 4: Isolation Forest\n",
    " from sklearn.ensemble import IsolationForest\n",
    " isolation_forest = IsolationForest(contamination=0.05, random_state=42)\n",
    " outlier_labels = isolation_forest.fit_predict(data)\n",
    " outliers['Isolation Forest'] = outlier_labels == -1\n",
    "\n",
    " return outliers\n",
    "\n",
    "# Detect outliers in marketing spend vs sales revenue relationship\n",
    "outliers = detect_outliers_multiple_methods(\n",
    " df['marketing_spend'].values,\n",
    " df['sales_revenue'].values\n",
    ")\n",
    "\n",
    "# Create comprehensive outlier visualization\n",
    "fig = make_subplots(\n",
    " rows=2, cols=2,\n",
    " subplot_titles=list(outliers.keys()),\n",
    " specs=[[{\"type\": \"scatter\"}, {\"type\": \"scatter\"}],\n",
    " [{\"type\": \"scatter\"}, {\"type\": \"scatter\"}]]\n",
    ")\n",
    "\n",
    "positions = [(1,1), (1,2), (2,1), (2,2)]\n",
    "colors = ['red', 'green', 'blue', 'purple']\n",
    "\n",
    "for i, (method, outlier_mask) in enumerate(outliers.items()):\n",
    " row, col = positions[i]\n",
    "\n",
    " # Normal points\n",
    " normal_mask = ~outlier_mask\n",
    " fig.add_trace(\n",
    " go.Scatter(\n",
    " x=df['marketing_spend'][normal_mask],\n",
    " y=df['sales_revenue'][normal_mask],\n",
    " mode='markers',\n",
    " marker=dict(size=5, opacity=0.6, color='lightblue'),\n",
    " name='Normal',\n",
    " showlegend=(i==0)\n",
    " ),\n",
    " row=row, col=col\n",
    " )\n",
    "\n",
    " # Outlier points\n",
    " if np.any(outlier_mask):\n",
    " fig.add_trace(\n",
    " go.Scatter(\n",
    " x=df['marketing_spend'][outlier_mask],\n",
    " y=df['sales_revenue'][outlier_mask],\n",
    " mode='markers',\n",
    " marker=dict(size=8, color=colors[i], symbol='x'),\n",
    " name='Outliers',\n",
    " showlegend=(i==0)\n",
    " ),\n",
    " row=row, col=col\n",
    " )\n",
    "\n",
    "fig.update_layout(\n",
    " title=\"Outlier Detection: Multiple Methods Comparison\",\n",
    " height=600,\n",
    " showlegend=True\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Summary statistics for outlier detection\n",
    "print(\" Outlier Detection Summary:\")\n",
    "for method, outlier_mask in outliers.items():\n",
    " n_outliers = np.sum(outlier_mask)\n",
    " percentage = (n_outliers / len(df)) * 100\n",
    " print(f\"• {method}: {n_outliers} outliers ({percentage:.1f}%)\")\n",
    "\n",
    "# Analyze outlier characteristics\n",
    "print(\"\\n Outlier Characteristics Analysis:\")\n",
    "combined_outliers = np.any(list(outliers.values()), axis=0)\n",
    "if np.any(combined_outliers):\n",
    " outlier_data = df[combined_outliers]\n",
    " normal_data = df[~combined_outliers]\n",
    "\n",
    " print(f\"• Total unique outliers: {np.sum(combined_outliers)} ({np.sum(combined_outliers)/len(df)*100:.1f}%)\")\n",
    " print(f\"• Average marketing spend - Outliers: ${outlier_data['marketing_spend'].mean():,.0f}\")\n",
    " print(f\"• Average marketing spend - Normal: ${normal_data['marketing_spend'].mean():,.0f}\")\n",
    " print(f\"• Average sales revenue - Outliers: ${outlier_data['sales_revenue'].mean():,.0f}\")\n",
    " print(f\"• Average sales revenue - Normal: ${normal_data['sales_revenue'].mean():,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8957df89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. INTERACTIVE SCATTER PLOT DASHBOARD\n",
    "print(\"\\n 5. INTERACTIVE SCATTER PLOT DASHBOARD\")\n",
    "print(\"=\" * 42)\n",
    "\n",
    "# Create comprehensive interactive dashboard\n",
    "def create_interactive_scatter_dashboard(dataframe):\n",
    " \"\"\"Create an interactive scatter plot dashboard with multiple features\"\"\"\n",
    "\n",
    " # Main scatter plot with dropdown selectors\n",
    " fig = go.Figure()\n",
    "\n",
    " # Default plot: Marketing vs Sales\n",
    " fig.add_trace(\n",
    " go.Scatter(\n",
    " x=dataframe['marketing_spend'],\n",
    " y=dataframe['sales_revenue'],\n",
    " mode='markers',\n",
    " marker=dict(\n",
    " size=8,\n",
    " opacity=0.7,\n",
    " color=dataframe['customer_satisfaction'],\n",
    " colorscale='viridis',\n",
    " showscale=True,\n",
    " colorbar=dict(title=\"Customer Satisfaction\")\n",
    " ),\n",
    " text=dataframe['region'],\n",
    " hovertemplate=(\n",
    " \"<b>Marketing:</b> $%{x:,.0f}<br>\"\n",
    " \"<b>Sales:</b> $%{y:,.0f}<br>\"\n",
    " \"<b>Region:</b> %{text}<br>\"\n",
    " \"<b>Satisfaction:</b> %{marker.color:.1f}/10\"\n",
    " \"<extra></extra>\"\n",
    " ),\n",
    " name='Business Data'\n",
    " )\n",
    " )\n",
    "\n",
    " # Add dropdown menus for X and Y axes\n",
    " fig.update_layout(\n",
    " updatemenus=[\n",
    " dict(\n",
    " buttons=list([\n",
    " dict(label=\"Marketing vs Sales\",\n",
    " method=\"restyle\",\n",
    " args=[{\"x\": [dataframe['marketing_spend']],\n",
    " \"y\": [dataframe['sales_revenue']]}]),\n",
    " dict(label=\"Price vs Demand\",\n",
    " method=\"restyle\",\n",
    " args=[{\"x\": [dataframe['product_price']],\n",
    " \"y\": [dataframe['demand']]}]),\n",
    " dict(label=\"Employees vs Revenue/Employee\",\n",
    " method=\"restyle\",\n",
    " args=[{\"x\": [dataframe['employee_count']],\n",
    " \"y\": [dataframe['revenue_per_employee']]}]),\n",
    " dict(label=\"Ad Budget vs Brand Awareness\",\n",
    " method=\"restyle\",\n",
    " args=[{\"x\": [dataframe['advertising_budget']],\n",
    " \"y\": [dataframe['brand_awareness']]}])\n",
    " ]),\n",
    " direction=\"down\",\n",
    " showactive=True,\n",
    " x=0.01,\n",
    " xanchor=\"left\",\n",
    " y=1.02,\n",
    " yanchor=\"top\"\n",
    " ),\n",
    " ]\n",
    " )\n",
    "\n",
    " fig.update_layout(\n",
    " title=\"Interactive Scatter Plot Dashboard<br><sub>Use dropdown to explore different relationships</sub>\",\n",
    " xaxis_title=\"X Variable\",\n",
    " yaxis_title=\"Y Variable\",\n",
    " height=600,\n",
    " width=900\n",
    " )\n",
    "\n",
    " return fig\n",
    "\n",
    "# Create and display interactive dashboard\n",
    "dashboard_fig = create_interactive_scatter_dashboard(df)\n",
    "dashboard_fig.show()\n",
    "\n",
    "# Animated scatter plot showing evolution over time\n",
    "print(\"\\n 5.1 Animated Time Series Scatter Plot:\")\n",
    "\n",
    "# Create time-based animation\n",
    "fig_anim = px.scatter(\n",
    " df.sort_values('time_period'),\n",
    " x='marketing_spend',\n",
    " y='sales_revenue',\n",
    " animation_frame='time_period',\n",
    " size='employee_count',\n",
    " color='region',\n",
    " hover_name='business_type',\n",
    " title=\"Business Performance Evolution Over Time\",\n",
    " labels={\n",
    " 'marketing_spend': 'Marketing Spend ($)',\n",
    " 'sales_revenue': 'Sales Revenue ($)',\n",
    " 'time_period': 'Time Period'\n",
    " },\n",
    " range_x=[df['marketing_spend'].min()*0.9, df['marketing_spend'].max()*1.1],\n",
    " range_y=[df['sales_revenue'].min()*0.9, df['sales_revenue'].max()*1.1],\n",
    " size_max=20\n",
    ")\n",
    "\n",
    "# Enhance animation settings\n",
    "fig_anim.update_layout(\n",
    " updatemenus=[dict(\n",
    " type=\"buttons\",\n",
    " direction=\"left\",\n",
    " buttons=list([\n",
    " dict(label=\"Play\",\n",
    " method=\"animate\",\n",
    " args=[None, {\"frame\": {\"duration\": 100, \"redraw\": False},\n",
    " \"fromcurrent\": True}]),\n",
    " dict(label=\"Pause\",\n",
    " method=\"animate\",\n",
    " args=[[None], {\"frame\": {\"duration\": 0, \"redraw\": False},\n",
    " \"mode\": \"immediate\",\n",
    " \"transition\": {\"duration\": 0}}])\n",
    " ]),\n",
    " pad={\"r\": 10, \"t\": 87},\n",
    " showactive=False,\n",
    " x=0.011,\n",
    " xanchor=\"right\",\n",
    " y=0,\n",
    " yanchor=\"top\"\n",
    " )]\n",
    ")\n",
    "\n",
    "fig_anim.show()\n",
    "\n",
    "print(\" Interactive Features Available:\")\n",
    "print(\"• Dropdown menus for exploring different variable relationships\")\n",
    "print(\"• Color encoding for third-dimension insights\")\n",
    "print(\"• Hover information with detailed business metrics\")\n",
    "print(\"• Animation showing temporal evolution of relationships\")\n",
    "print(\"• Zoom and pan capabilities for detailed exploration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7f371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. CORRELATION MATRIX AND PAIR PLOTS\n",
    "print(\"\\n 6. CORRELATION MATRIX AND PAIR PLOTS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Select numerical variables for correlation analysis\n",
    "numerical_vars = ['marketing_spend', 'sales_revenue', 'customer_acq_cost',\n",
    " 'customer_satisfaction', 'product_price', 'demand',\n",
    " 'employee_count', 'revenue_per_employee', 'advertising_budget',\n",
    " 'brand_awareness']\n",
    "\n",
    "correlation_matrix = df[numerical_vars].corr()\n",
    "\n",
    "# Create interactive correlation heatmap\n",
    "fig_corr = go.Figure(data=go.Heatmap(\n",
    " z=correlation_matrix.values,\n",
    " x=correlation_matrix.columns,\n",
    " y=correlation_matrix.columns,\n",
    " colorscale='RdBu_r',\n",
    " zmid=0,\n",
    " text=correlation_matrix.round(3).values,\n",
    " texttemplate=\"%{text}\",\n",
    " textfont={\"size\": 10},\n",
    " hoverongaps=False,\n",
    " hovertemplate=\"<b>%{y} vs %{x}</b><br>Correlation: %{z:.3f}<extra></extra>\"\n",
    "))\n",
    "\n",
    "fig_corr.update_layout(\n",
    " title=\"Business Metrics Correlation Matrix\",\n",
    " width=800,\n",
    " height=600,\n",
    " xaxis_title=\"Variables\",\n",
    " yaxis_title=\"Variables\"\n",
    ")\n",
    "fig_corr.show()\n",
    "\n",
    "# Create enhanced pair plot\n",
    "print(\"\\n6.1 Enhanced Pair Plot Analysis:\")\n",
    "\n",
    "# Select key variables for pair plot\n",
    "key_vars = ['marketing_spend', 'sales_revenue', 'customer_satisfaction', 'product_price']\n",
    "pair_data = df[key_vars + ['region']].copy()\n",
    "\n",
    "# Create pair plot matrix\n",
    "n_vars = len(key_vars)\n",
    "fig_pair = make_subplots(\n",
    " rows=n_vars, cols=n_vars,\n",
    " subplot_titles=[f\"{row} vs {col}\" if row != col else f\"{row} Distribution\"\n",
    " for row in key_vars for col in key_vars]\n",
    ")\n",
    "\n",
    "for i, var1 in enumerate(key_vars):\n",
    " for j, var2 in enumerate(key_vars):\n",
    " if i == j:\n",
    " # Diagonal: Distribution plot\n",
    " fig_pair.add_trace(\n",
    " go.Histogram(\n",
    " x=df[var1],\n",
    " nbinsx=20,\n",
    " name=f'{var1} Dist',\n",
    " showlegend=False,\n",
    " marker_color='lightblue',\n",
    " opacity=0.7\n",
    " ),\n",
    " row=i+1, col=j+1\n",
    " )\n",
    " else:\n",
    " # Off-diagonal: Scatter plot colored by region\n",
    " for region in df['region'].unique():\n",
    " region_data = df[df['region'] == region]\n",
    " fig_pair.add_trace(\n",
    " go.Scatter(\n",
    " x=region_data[var2],\n",
    " y=region_data[var1],\n",
    " mode='markers',\n",
    " marker=dict(size=4, opacity=0.6),\n",
    " name=region if i == 0 and j == 1 else None,\n",
    " showlegend=(i == 0 and j == 1),\n",
    " legendgroup=region\n",
    " ),\n",
    " row=i+1, col=j+1\n",
    " )\n",
    "\n",
    "fig_pair.update_layout(\n",
    " title=\"Enhanced Pair Plot: Key Business Variables by Region\",\n",
    " height=800,\n",
    " showlegend=True\n",
    ")\n",
    "fig_pair.show()\n",
    "\n",
    "# Correlation strength analysis\n",
    "print(\"\\n Correlation Strength Analysis:\")\n",
    "correlations_list = []\n",
    "\n",
    "for i in range(len(numerical_vars)):\n",
    " for j in range(i+1, len(numerical_vars)):\n",
    " var1, var2 = numerical_vars[i], numerical_vars[j]\n",
    " corr_val = correlation_matrix.loc[var1, var2]\n",
    "\n",
    " correlations_list.append({\n",
    " 'Variable_1': var1,\n",
    " 'Variable_2': var2,\n",
    " 'Correlation': corr_val,\n",
    " 'Abs_Correlation': abs(corr_val),\n",
    " 'Strength': 'Very Strong' if abs(corr_val) >= 0.8 else\n",
    " 'Strong' if abs(corr_val) >= 0.6 else\n",
    " 'Moderate' if abs(corr_val) >= 0.4 else\n",
    " 'Weak' if abs(corr_val) >= 0.2 else 'Very Weak',\n",
    " 'Direction': 'Positive' if corr_val > 0 else 'Negative'\n",
    " })\n",
    "\n",
    "corr_df = pd.DataFrame(correlations_list)\n",
    "corr_df = corr_df.sort_values('Abs_Correlation', ascending=False)\n",
    "\n",
    "print(\"Top 10 Strongest Correlations:\")\n",
    "print(corr_df.head(10)[['Variable_1', 'Variable_2', 'Correlation', 'Strength', 'Direction']].to_string(index=False))\n",
    "\n",
    "# Create correlation strength distribution\n",
    "fig_strength = px.histogram(\n",
    " corr_df,\n",
    " x='Abs_Correlation',\n",
    " color='Strength',\n",
    " title=\"Distribution of Correlation Strengths in Business Data\",\n",
    " labels={'Abs_Correlation': 'Absolute Correlation Coefficient'},\n",
    " nbins=20\n",
    ")\n",
    "fig_strength.show()\n",
    "\n",
    "print(f\"\\n Key Correlation Insights:\")\n",
    "strong_corrs = corr_df[corr_df['Abs_Correlation'] >= 0.6]\n",
    "print(f\"• {len(strong_corrs)} strong correlations (|r| ≥ 0.6) identified\")\n",
    "print(f\"• Strongest positive correlation: {corr_df.iloc[0]['Variable_1']} vs {corr_df.iloc[0]['Variable_2']} (r={corr_df.iloc[0]['Correlation']:.3f})\")\n",
    "\n",
    "negative_corrs = corr_df[corr_df['Correlation'] < 0].sort_values('Correlation')\n",
    "if not negative_corrs.empty:\n",
    " print(f\"• Strongest negative correlation: {negative_corrs.iloc[0]['Variable_1']} vs {negative_corrs.iloc[0]['Variable_2']} (r={negative_corrs.iloc[0]['Correlation']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb0362a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. BUSINESS INSIGHTS AND INTERPRETATION\n",
    "print(\"\\n 7. BUSINESS INSIGHTS AND INTERPRETATION\")\n",
    "print(\"=\" * 46)\n",
    "\n",
    "def generate_business_insights(dataframe, correlation_data):\n",
    " \"\"\"Generate actionable business insights from scatter plot analysis\"\"\"\n",
    "\n",
    " insights = {\n",
    " 'high_impact_relationships': [],\n",
    " 'optimization_opportunities': [],\n",
    " 'risk_factors': [],\n",
    " 'strategic_recommendations': []\n",
    " }\n",
    "\n",
    " # Analyze high-impact relationships\n",
    " marketing_sales_corr = dataframe['marketing_spend'].corr(dataframe['sales_revenue'])\n",
    " price_demand_corr = dataframe['product_price'].corr(dataframe['demand'])\n",
    "\n",
    " if marketing_sales_corr > 0.7:\n",
    " insights['high_impact_relationships'].append(\n",
    " f\"Strong marketing ROI: Every $1 in marketing generates ~${marketing_sales_corr * 2:.2f} in sales\"\n",
    " )\n",
    "\n",
    " if price_demand_corr < -0.5:\n",
    " insights['optimization_opportunities'].append(\n",
    " \"Price elasticity analysis shows demand sensitivity - consider dynamic pricing strategies\"\n",
    " )\n",
    "\n",
    " # Identify outliers as opportunities or risks\n",
    " outliers_combined = np.any(list(outliers.values()), axis=0)\n",
    " outlier_performance = dataframe[outliers_combined]\n",
    "\n",
    " if not outlier_performance.empty:\n",
    " high_performers = outlier_performance[\n",
    " outlier_performance['sales_revenue'] > dataframe['sales_revenue'].quantile(0.9)\n",
    " ]\n",
    "\n",
    " if not high_performers.empty:\n",
    " insights['optimization_opportunities'].append(\n",
    " f\"Found {len(high_performers)} high-performing outliers with unique patterns worth replicating\"\n",
    " )\n",
    "\n",
    " # Customer satisfaction impact\n",
    " satisfaction_impact = dataframe.groupby(\n",
    " pd.cut(dataframe['customer_satisfaction'], bins=3, labels=['Low', 'Medium', 'High'])\n",
    " )['sales_revenue'].mean()\n",
    "\n",
    " if satisfaction_impact['High'] > satisfaction_impact['Low'] * 1.2:\n",
    " insights['strategic_recommendations'].append(\n",
    " \"Customer satisfaction shows strong correlation with revenue - prioritize customer experience investments\"\n",
    " )\n",
    "\n",
    " # Regional performance analysis\n",
    " regional_performance = dataframe.groupby('region').agg({\n",
    " 'sales_revenue': 'mean',\n",
    " 'marketing_spend': 'mean',\n",
    " 'customer_satisfaction': 'mean'\n",
    " })\n",
    "\n",
    " best_region = regional_performance['sales_revenue'].idxmax()\n",
    " worst_region = regional_performance['sales_revenue'].idxmin()\n",
    "\n",
    " insights['strategic_recommendations'].append(\n",
    " f\"Regional optimization: {best_region} region outperforms {worst_region} by \"\n",
    " f\"{((regional_performance.loc[best_region, 'sales_revenue'] / regional_performance.loc[worst_region, 'sales_revenue']) - 1) * 100:.1f}%\"\n",
    " )\n",
    "\n",
    " return insights\n",
    "\n",
    "# Generate comprehensive business insights\n",
    "business_insights = generate_business_insights(df, corr_df)\n",
    "\n",
    "# Create business insight visualization\n",
    "fig_insights = make_subplots(\n",
    " rows=2, cols=2,\n",
    " subplot_titles=(\n",
    " \"Marketing ROI by Region\",\n",
    " \"Customer Satisfaction Impact\",\n",
    " \"Price vs Demand Sensitivity\",\n",
    " \"Regional Performance Comparison\"\n",
    " ),\n",
    " specs=[[{\"type\": \"bar\"}, {\"type\": \"scatter\"}],\n",
    " [{\"type\": \"scatter\"}, {\"type\": \"bar\"}]]\n",
    ")\n",
    "\n",
    "# Marketing ROI by region\n",
    "regional_roi = df.groupby('region').apply(\n",
    " lambda x: x['sales_revenue'].sum() / x['marketing_spend'].sum()\n",
    ").reset_index()\n",
    "regional_roi.columns = ['region', 'roi']\n",
    "\n",
    "fig_insights.add_trace(\n",
    " go.Bar(\n",
    " x=regional_roi['region'],\n",
    " y=regional_roi['roi'],\n",
    " marker_color=['red', 'green', 'blue', 'orange'],\n",
    " name='Marketing ROI',\n",
    " text=regional_roi['roi'].round(2),\n",
    " textposition='auto'\n",
    " ),\n",
    " row=1, col=1\n",
    ")\n",
    "\n",
    "# Customer satisfaction impact\n",
    "satisfaction_bins = pd.cut(df['customer_satisfaction'], bins=5, labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
    "satisfaction_impact = df.groupby(satisfaction_bins)['sales_revenue'].mean().reset_index()\n",
    "\n",
    "fig_insights.add_trace(\n",
    " go.Scatter(\n",
    " x=satisfaction_impact['customer_satisfaction'],\n",
    " y=satisfaction_impact['sales_revenue'],\n",
    " mode='markers+lines',\n",
    " marker=dict(size=10, color='green'),\n",
    " line=dict(color='green', width=3),\n",
    " name='Satisfaction Impact'\n",
    " ),\n",
    " row=1, col=2\n",
    ")\n",
    "\n",
    "# Price sensitivity analysis\n",
    "fig_insights.add_trace(\n",
    " go.Scatter(\n",
    " x=df['product_price'],\n",
    " y=df['demand'],\n",
    " mode='markers',\n",
    " marker=dict(size=5, opacity=0.6, color='purple'),\n",
    " name='Price Sensitivity',\n",
    " trendline='ols'\n",
    " ),\n",
    " row=2, col=1\n",
    ")\n",
    "\n",
    "# Regional performance comparison\n",
    "regional_performance = df.groupby('region').agg({\n",
    " 'sales_revenue': 'mean',\n",
    " 'customer_satisfaction': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "fig_insights.add_trace(\n",
    " go.Bar(\n",
    " x=regional_performance['region'],\n",
    " y=regional_performance['sales_revenue'],\n",
    " marker_color=['lightcoral', 'lightgreen', 'lightblue', 'lightyellow'],\n",
    " name='Avg Sales Revenue',\n",
    " text=regional_performance['sales_revenue'].round(0),\n",
    " textposition='auto'\n",
    " ),\n",
    " row=2, col=2\n",
    ")\n",
    "\n",
    "fig_insights.update_layout(\n",
    " title=\"Business Intelligence Dashboard: Key Performance Insights\",\n",
    " height=700,\n",
    " showlegend=False\n",
    ")\n",
    "fig_insights.show()\n",
    "\n",
    "# Display business insights\n",
    "print(\" Strategic Business Insights:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "for category, insights_list in business_insights.items():\n",
    " if insights_list:\n",
    " print(f\"\\n{category.replace('_', ' ').title()}:\")\n",
    " for i, insight in enumerate(insights_list, 1):\n",
    " print(f\" {i}. {insight}\")\n",
    "\n",
    "# Key performance metrics\n",
    "print(f\"\\n Key Performance Metrics:\")\n",
    "print(f\"• Overall Marketing ROI: {df['sales_revenue'].sum() / df['marketing_spend'].sum():.2f}x\")\n",
    "print(f\"• Average Customer Satisfaction: {df['customer_satisfaction'].mean():.1f}/10\")\n",
    "print(f\"• Price Elasticity: {df['product_price'].corr(df['demand']):.3f}\")\n",
    "print(f\"• Employee Productivity: ${df['revenue_per_employee'].mean():,.0f} per employee\")\n",
    "\n",
    "# Recommendations summary\n",
    "print(f\"\\n Actionable Recommendations:\")\n",
    "print(\"1. Focus marketing investments in regions with highest ROI\")\n",
    "print(\"2. Implement customer satisfaction monitoring as leading indicator\")\n",
    "print(\"3. Consider premium pricing strategy where demand is less elastic\")\n",
    "print(\"4. Investigate outlier success patterns for replication opportunities\")\n",
    "print(\"5. Balance employee count with productivity metrics for optimal scaling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfecc3b",
   "metadata": {},
   "source": [
    "# LEARNING SUMMARY: Scatter Plot Analysis\n",
    "\n",
    "## Key Concepts Mastered\n",
    "\n",
    "### 1. **Scatter Plot Fundamentals**\n",
    "- **Basic Relationships**: Understanding positive, negative, and no correlation patterns\n",
    "- **Trend Analysis**: Linear, polynomial, and non-linear relationship identification\n",
    "- **Outlier Detection**: Multiple statistical methods for anomaly identification\n",
    "- **Confidence Intervals**: Understanding uncertainty in relationship estimates\n",
    "\n",
    "### 2. **Multi-Dimensional Visualization**\n",
    "- **Color Encoding**: Adding third dimension through color mapping\n",
    "- **Size Encoding**: Representing fourth dimension through marker size\n",
    "- **Symbol Encoding**: Using shapes for categorical distinctions\n",
    "- **Interactive Features**: Hover information, zooming, and dynamic exploration\n",
    "\n",
    "### 3. **Advanced Techniques**\n",
    "- **Polynomial Regression**: Capturing non-linear relationships\n",
    "- **Statistical Testing**: Correlation significance and confidence intervals\n",
    "- **Animation**: Temporal evolution of relationships\n",
    "- **Dashboard Creation**: Interactive exploration tools\n",
    "\n",
    "## Business Applications\n",
    "\n",
    "### Strategic Analysis\n",
    "- **Marketing ROI**: Quantifying marketing spend effectiveness\n",
    "- **Price Elasticity**: Understanding demand sensitivity to pricing\n",
    "- **Customer Insights**: Satisfaction impact on business outcomes\n",
    "- **Regional Performance**: Geographic optimization opportunities\n",
    "\n",
    "### Decision Support\n",
    "- Scatter plots provide:\n",
    " - Clear visual evidence for business decisions\n",
    " - Outlier identification for best practice replication\n",
    " - Trend analysis for forecasting and planning\n",
    " - Multi-factor relationship understanding\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Tier 2: Predictive Models** - Use scatter plot insights for regression modeling\n",
    "2. **Correlation to Causation** - Move from observational to causal analysis\n",
    "3. **Time Series Analysis** - Understand how relationships evolve over time\n",
    "4. **Advanced Visualization** - 3D plots and network analysis\n",
    "\n",
    "## Pro Tips\n",
    "\n",
    "- Always check for outliers - they often contain valuable insights\n",
    "- Use multiple encoding dimensions (color, size, shape) for richer analysis\n",
    "- Consider non-linear relationships, not just linear correlations\n",
    "- Interactive plots are powerful for stakeholder presentations\n",
    "- Combine statistical testing with visual analysis for robust conclusions\n",
    "\n",
    "## Common Pitfalls\n",
    "\n",
    "- **Correlation ≠ Causation**: Strong relationships don't prove cause-and-effect\n",
    "- **Outlier Sensitivity**: Extreme values can distort trend analysis\n",
    "- **Scale Effects**: Different variable scales can mislead visual interpretation\n",
    "- **Overplotting**: Too many points can obscure patterns in dense datasets\n",
    "\n",
    "**Remember**: *Scatter plots are your window into bivariate relationships - use them to guide deeper statistical analysis and business strategy!*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}