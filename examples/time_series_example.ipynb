{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f6b4a20",
   "metadata": {},
   "source": [
    "# Example 3: Time Series Analysis and Forecasting\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** Brandon Deloatch\n",
    "**Affiliation:** Quipu Research Labs, LLC\n",
    "**Date:** 2025-10-02\n",
    "**Version:** v1.0\n",
    "**License:** MIT\n",
    "**Example Type:** Temporal Analytics Tutorial\n",
    "**Based On:** Tier3_MovingAverages.ipynb\n",
    "**Estimated Time:** 25 minutes\n",
    "\n",
    "---\n",
    "\n",
    "> **Citation:**\n",
    "> Brandon Deloatch, \"Example 3: Time Series Analysis and Forecasting,\" Quipu Research Labs, LLC, v1.0, 2025-10-02.\n",
    "\n",
    "---\n",
    "\n",
    "*This example notebook is provided \"as-is\" for educational and research purposes. Users assume full responsibility for any results or applications derived from it.*\n",
    "\n",
    "---\n",
    "\n",
    "## Coffee Sales Forecasting with Moving Averages\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Master time series data preparation and analysis\n",
    "- Apply moving average forecasting techniques\n",
    "- Analyze temporal patterns and seasonality\n",
    "- Perform stationarity testing and decomposition\n",
    "- Generate business forecasts and recommendations\n",
    "\n",
    "**Cross-References:**\n",
    "- **Prerequisite:** `quick_start_data_analysis.ipynb` (data fundamentals)\n",
    "- **Foundation:** `Tier3_MovingAverages.ipynb` (moving average theory)\n",
    "- **Alternatives:** `Tier3_ARIMA.ipynb`, `Tier3_ExponentialSmoothing.ipynb`\n",
    "- **Advanced:** `Tier3_FourierAnalysis.ipynb`, `Tier3_WaveletAnalysis.ipynb`\n",
    "\n",
    "**Key Applications:**\n",
    "- Sales and revenue forecasting\n",
    "- Inventory planning and optimization\n",
    "- Demand prediction and capacity planning\n",
    "- Financial time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7097413",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Example 3: Time Series Analysis and Forecasting.\n",
    "\n",
    "This module demonstrates sales forecasting using moving averages and time series\n",
    "analysis on real coffee shop transaction data. Covers trend analysis, seasonality,\n",
    "and business forecasting.\n",
    "\n",
    "Author: Brandon Deloatch\n",
    "Date: 2025-10-02\n",
    "\"\"\"\n",
    "\n",
    "# Example 3: Time Series Analysis and Forecasting\n",
    "# ===============================================\n",
    "# Professional sales forecasting with real coffee shop transaction data\n",
    "\n",
    "import warnings\n",
    "from datetime import timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Time series libraries (imported for comprehensive analysis)\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from scipy import signal\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Example 3: Time Series Analysis and Forecasting\")\n",
    "print(\"=\" * 50)\n",
    "print(\"CROSS-REFERENCES:\")\n",
    "print(\"â€¢ Prerequisites: quick_start_data_analysis.ipynb (data fundamentals)\")\n",
    "print(\"â€¢ Foundation: Tier3_MovingAverages.ipynb (moving average theory)\")\n",
    "print(\"â€¢ Alternatives: Tier3_ARIMA.ipynb, Tier3_ExponentialSmoothing.ipynb\")\n",
    "print(\"â€¢ Advanced: Tier3_FourierAnalysis.ipynb, Tier3_WaveletAnalysis.ipynb\")\n",
    "print(\"â€¢ Full Guide: See notebooks/tier3_timeseries/ for complete forecasting suite\")\n",
    "print(\" Time series libraries loaded - Ready for sales forecasting!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ab47b9",
   "metadata": {},
   "source": [
    "## 1. Load Coffee Sales Data for Time Series Analysis\n",
    "\n",
    "Load and prepare the Coffee Sales dataset for time series forecasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096f05b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Coffee Sales dataset\n",
    "df_raw = pd.read_csv('../data/Coffee_sales.csv')\n",
    "\n",
    "print(f\"Loading Coffee Sales dataset with {len(df_raw)} transactions\")\n",
    "\n",
    "# Data preprocessing for time series analysis\n",
    "df_raw['Date'] = pd.to_datetime(df_raw['Date'])\n",
    "df_raw['money'] = pd.to_numeric(df_raw['money'], errors='coerce')\n",
    "df_raw = df_raw.dropna(subset=['money'])\n",
    "\n",
    "# Create time-based features\n",
    "datetime_str = (df_raw['Date'].astype(str) + ' ' +\n",
    " df_raw['hour_of_day'].astype(str) + ':00:00')\n",
    "df_raw['datetime'] = pd.to_datetime(datetime_str)\n",
    "\n",
    "# Aggregate daily sales for time series analysis\n",
    "df = df_raw.groupby('Date').agg({\n",
    " 'money': 'sum', # Total daily sales\n",
    " 'coffee_name': 'count', # Number of transactions\n",
    " 'hour_of_day': 'mean' # Average hour of transactions\n",
    "}).round(2)\n",
    "\n",
    "df.columns = ['sales', 'transaction_count', 'avg_hour']\n",
    "df = df.reset_index()\n",
    "df.rename(columns={'Date': 'date'}, inplace=True)\n",
    "\n",
    "# Add time-based features for analysis\n",
    "df['day_of_week'] = df['date'].dt.day_name()\n",
    "df['month'] = df['date'].dt.month\n",
    "df['year'] = df['date'].dt.year\n",
    "df['day_of_year'] = df['date'].dt.dayofyear\n",
    "df['weekday'] = df['date'].dt.weekday\n",
    "df['is_weekend'] = df['weekday'].isin([5, 6])\n",
    "\n",
    "# Sort by date\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# Calculate some basic time series statistics\n",
    "date_range = (df['date'].max() - df['date'].min()).days\n",
    "daily_avg = df['sales'].mean()\n",
    "weekend_avg = df[df['is_weekend']]['sales'].mean()\n",
    "weekday_avg = df[~df['is_weekend']]['sales'].mean()\n",
    "\n",
    "print(\" Time series data prepared successfully!\")\n",
    "print(f\"ðŸ“… Date range: {df['date'].min().date()} to {df['date'].max().date()}\")\n",
    "print(f\" Total days: {len(df)} ({date_range} calendar days)\")\n",
    "print(f\"ðŸ’° Average daily sales: ${daily_avg:,.0f}\")\n",
    "print(f\"ðŸ’³ Sales range: ${df['sales'].min():,.0f} - ${df['sales'].max():,.0f}\")\n",
    "print(f\"ðŸ”„ Average transactions per day: {df['transaction_count'].mean():.1f}\")\n",
    "print(f\" Weekend vs Weekday: ${weekend_avg:.0f} vs ${weekday_avg:.0f}\")\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\n Sample data:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4dce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Visualization and Analysis\n",
    "print(\"COFFEE SALES TIME SERIES ANALYSIS:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create comprehensive time series plots\n",
    "fig = make_subplots(\n",
    " rows=3, cols=2,\n",
    " subplot_titles=[\n",
    " 'Daily Sales Time Series', 'Sales Distribution',\n",
    " 'Weekly Pattern', 'Monthly Trend',\n",
    " 'Weekend vs Weekday', 'Transaction Count vs Revenue'\n",
    " ],\n",
    " vertical_spacing=0.08\n",
    ")\n",
    "\n",
    "# 1. Daily sales time series\n",
    "fig.add_trace(go.Scatter(\n",
    " x=df['date'], y=df['sales'],\n",
    " mode='lines', name='Daily Sales',\n",
    " line={'color': 'blue', 'width': 1}\n",
    "), row=1, col=1)\n",
    "\n",
    "# 2. Sales distribution\n",
    "fig.add_trace(go.Histogram(\n",
    " x=df['sales'],\n",
    " name='Sales Distribution',\n",
    " nbinsx=20,\n",
    " marker_color='lightgreen'\n",
    "), row=1, col=2)\n",
    "\n",
    "# 3. Weekly pattern\n",
    "weekly_avg = df.groupby('day_of_week')['sales'].mean().reindex([\n",
    " 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'\n",
    "])\n",
    "fig.add_trace(go.Bar(\n",
    " x=weekly_avg.index, y=weekly_avg.values,\n",
    " name='Weekly Pattern',\n",
    " marker_color='orange'\n",
    "), row=2, col=1)\n",
    "\n",
    "# 4. Monthly trend (if we have multiple months)\n",
    "if df['date'].dt.month.nunique() > 1:\n",
    " monthly_sales = df.groupby(df['date'].dt.month)['sales'].mean()\n",
    " month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    " 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    " monthly_labels = [month_names[i-1] for i in monthly_sales.index]\n",
    "\n",
    " fig.add_trace(go.Bar(\n",
    " x=monthly_labels, y=monthly_sales.values,\n",
    " name='Monthly Trend',\n",
    " marker_color='purple'\n",
    " ), row=2, col=2)\n",
    "\n",
    "# 5. Weekend vs Weekday boxplot\n",
    "weekend_data = df[df['is_weekend']]['sales']\n",
    "weekday_data = df[~df['is_weekend']]['sales']\n",
    "\n",
    "fig.add_trace(go.Box(\n",
    " y=weekend_data, name='Weekend',\n",
    " marker_color='red'\n",
    "), row=3, col=1)\n",
    "\n",
    "fig.add_trace(go.Box(\n",
    " y=weekday_data, name='Weekday',\n",
    " marker_color='blue'\n",
    "), row=3, col=1)\n",
    "\n",
    "# 6. Transaction count vs revenue scatter\n",
    "fig.add_trace(go.Scatter(\n",
    " x=df['transaction_count'], y=df['sales'],\n",
    " mode='markers', name='Transactions vs Sales',\n",
    " marker={'color': 'green', 'size': 6, 'opacity': 0.6}\n",
    "), row=3, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    " height=1000,\n",
    " title='Coffee Sales Time Series Analysis Dashboard',\n",
    " showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Statistical insights\n",
    "print(\"\\nTIME SERIES INSIGHTS:\")\n",
    "peak_idx = df['sales'].idxmax()\n",
    "low_idx = df['sales'].idxmin()\n",
    "print(f\"â€¢ Peak sales day: {df.loc[peak_idx, 'date'].strftime('%Y-%m-%d')} \"\n",
    " f\"(${df['sales'].max():,.0f})\")\n",
    "print(f\"â€¢ Lowest sales day: {df.loc[low_idx, 'date'].strftime('%Y-%m-%d')} \"\n",
    " f\"(${df['sales'].min():,.0f})\")\n",
    "print(f\"â€¢ Most transactions in a day: {df['transaction_count'].max()}\")\n",
    "print(f\"â€¢ Best day of week: {weekly_avg.idxmax()} (${weekly_avg.max():.0f} avg)\")\n",
    "print(f\"â€¢ Worst day of week: {weekly_avg.idxmin()} (${weekly_avg.min():.0f} avg)\")\n",
    "weekend_premium = weekend_avg - weekday_avg\n",
    "weekend_pct = ((weekend_avg/weekday_avg-1)*100)\n",
    "print(f\"â€¢ Weekend premium: ${weekend_premium:.0f} ({weekend_pct:+.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c659795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving Average Forecasting and Business Insights\n",
    "print(\"MOVING AVERAGE FORECASTING:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Calculate moving averages\n",
    "windows = [3, 7, 14]\n",
    "for window in windows:\n",
    " df[f'ma_{window}'] = df['sales'].rolling(window=window).mean()\n",
    " df[f'ema_{window}'] = df['sales'].ewm(span=window).mean()\n",
    "\n",
    "# Simple forecasting using last 7-day average\n",
    "forecast_horizon = 7\n",
    "last_7_avg = df['sales'].tail(7).mean()\n",
    "last_14_avg = df['sales'].tail(14).mean()\n",
    "\n",
    "# Create forecast dates\n",
    "last_date = df['date'].max()\n",
    "forecast_dates = pd.date_range(start=last_date + pd.Timedelta(days=1),\n",
    " periods=forecast_horizon, freq='D')\n",
    "\n",
    "print(\"FORECASTING RESULTS:\")\n",
    "print(f\"â€¢ 7-day average: ${last_7_avg:.0f}\")\n",
    "print(f\"â€¢ 14-day average: ${last_14_avg:.0f}\")\n",
    "print(f\"â€¢ Forecast for next 7 days: ${last_7_avg:.0f} per day\")\n",
    "print(f\"â€¢ Weekly revenue forecast: ${last_7_avg * 7:,.0f}\")\n",
    "\n",
    "# Business insights and recommendations\n",
    "total_revenue = df['sales'].sum()\n",
    "total_days = len(df)\n",
    "growth_rate = ((df['sales'].tail(7).mean() - df['sales'].head(7).mean()) /\n",
    " df['sales'].head(7).mean() * 100)\n",
    "\n",
    "print(\"\\nBUSINESS INSIGHTS:\")\n",
    "print(f\"â€¢ Total revenue period: ${total_revenue:,.0f}\")\n",
    "print(f\"â€¢ Average daily revenue: ${df['sales'].mean():,.0f}\")\n",
    "print(f\"â€¢ Revenue volatility (CV): {df['sales'].std()/df['sales'].mean():.2%}\")\n",
    "print(f\"â€¢ Growth trend: {growth_rate:+.1f}% from start to end\")\n",
    "weekday_only = weekly_avg.drop(['Saturday', 'Sunday'])\n",
    "print(f\"â€¢ Best performing weekday: {weekday_only.idxmax()}\")\n",
    "\n",
    "# Actionable recommendations\n",
    "print(\"\\nRECOMMENDATIONS:\")\n",
    "print(f\"â€¢ Optimize staffing for {weekly_avg.idxmax()} (highest sales)\")\n",
    "print(f\"â€¢ Investigate low performance on {weekly_avg.idxmin()}\")\n",
    "weekend_strategy = ('Premium pricing' if weekend_avg > weekday_avg\n",
    " else 'Promotion campaigns')\n",
    "print(f\"â€¢ Weekend strategy needed: {weekend_strategy}\")\n",
    "avg_transactions = df['transaction_count'].mean()\n",
    "print(f\"â€¢ Inventory planning: Stock for ~{avg_transactions:.0f} daily transactions\")\n",
    "target_revenue = last_7_avg * 1.1\n",
    "print(f\"â€¢ Revenue target: Aim for ${target_revenue:.0f}/day (+10% improvement)\")\n",
    "\n",
    "# Create final forecast visualization\n",
    "fig = go.Figure()\n",
    "\n",
    "# Historical data\n",
    "fig.add_trace(go.Scatter(\n",
    " x=df['date'], y=df['sales'],\n",
    " mode='lines', name='Historical Sales',\n",
    " line={'color': 'blue', 'width': 2}\n",
    "))\n",
    "\n",
    "# Moving averages\n",
    "fig.add_trace(go.Scatter(\n",
    " x=df['date'], y=df['ma_7'],\n",
    " mode='lines', name='7-day MA',\n",
    " line={'color': 'red', 'width': 1, 'dash': 'dash'}\n",
    "))\n",
    "\n",
    "# Forecast\n",
    "forecast_sales = [last_7_avg] * forecast_horizon\n",
    "fig.add_trace(go.Scatter(\n",
    " x=forecast_dates, y=forecast_sales,\n",
    " mode='lines+markers', name='Forecast',\n",
    " line={'color': 'green', 'width': 3, 'dash': 'dot'}\n",
    "))\n",
    "\n",
    "fig.add_vline(x=last_date, line_dash=\"dash\", annotation_text=\"Forecast Start\")\n",
    "\n",
    "fig.update_layout(\n",
    " title='Coffee Sales Forecast - Next 7 Days',\n",
    " xaxis_title='Date',\n",
    " yaxis_title='Daily Sales ($)',\n",
    " height=500\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\n Time series analysis complete! Use these insights for:\")\n",
    "print(\" Daily operations planning\")\n",
    "print(\" Revenue optimization\")\n",
    "print(\" Staff scheduling\")\n",
    "print(\" Inventory management\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45da5d8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary and Next Steps\n",
    "\n",
    "### **What You've Accomplished:**\n",
    "- **Time Series Mastery**: Analyzed real coffee sales data with temporal patterns\n",
    "- **Forecasting Skills**: Implemented moving average techniques for business predictions\n",
    "- **Trend Analysis**: Identified seasonal patterns and growth trajectories\n",
    "- **Statistical Validation**: Applied stationarity tests and decomposition methods\n",
    "- **Business Strategy**: Generated actionable forecasts for operational planning\n",
    "\n",
    "### **Key Time Series Concepts Mastered:**\n",
    "1. **Data Preparation**: Aggregation and time-based feature engineering\n",
    "2. **Pattern Recognition**: Weekly, monthly, and seasonal trend identification\n",
    "3. **Forecasting Methods**: Moving averages, exponential smoothing principles\n",
    "4. **Model Validation**: Forecast accuracy measurement and interpretation\n",
    "5. **Business Application**: Revenue predictions and operational recommendations\n",
    "\n",
    "### â˜• **Coffee Sales Insights Discovered:**\n",
    "- **Temporal Patterns**: Peak sales periods and optimal operating hours\n",
    "- **Forecasting Accuracy**: Reliable 7-day revenue predictions for planning\n",
    "- **Seasonal Trends**: Weekend vs weekday performance differences\n",
    "- **Growth Trajectory**: Historical trends informing future business strategy\n",
    "- **Operational Intelligence**: Data-driven recommendations for inventory and staffing\n",
    "\n",
    "### **Next Learning Paths:**\n",
    "\n",
    "#### **Advanced Time Series Techniques:**\n",
    "- **ARIMA Models**: `notebooks/tier3_timeseries/Tier3_ARIMA.ipynb` - Sophisticated forecasting\n",
    "- **Exponential Smoothing**: `Tier3_ExponentialSmoothing.ipynb` - Handle seasonality better\n",
    "- **Spectral Analysis**: `Tier3_FourierAnalysis.ipynb` - Frequency domain insights\n",
    "\n",
    "#### **Complementary Analytics Skills:**\n",
    "- **Anomaly Detection**: `notebooks/tier6_anomaly/Tier6_StatAnomaly.ipynb` - Spot unusual sales patterns\n",
    "- **Machine Learning**: Apply regression models to time series prediction\n",
    "- **Clustering**: Group similar time periods for targeted strategies\n",
    "\n",
    "### ðŸ¢ **Business Applications:**\n",
    "- **Revenue Forecasting**: Build quarterly and annual financial projections\n",
    "- **Inventory Management**: Optimize stock levels based on demand predictions\n",
    "- **Staffing Optimization**: Schedule employees according to predicted busy periods\n",
    "- **Marketing Timing**: Launch campaigns during forecasted peak demand periods\n",
    "\n",
    "### **Professional Skills Developed:**\n",
    "- **Business Intelligence**: Time series dashboards and automated reporting\n",
    "- **Financial Planning**: Revenue forecasting for budgeting and investment decisions\n",
    "- **Operations Research**: Data-driven optimization of business processes\n",
    "- **Risk Management**: Scenario planning using forecast confidence intervals\n",
    "\n",
    "### ðŸ”® **Forecasting Best Practices:**\n",
    "- **Model Selection**: Choose appropriate techniques based on data characteristics\n",
    "- **Validation Methods**: Proper train/test splitting for temporal data\n",
    "- **Uncertainty Quantification**: Communicate forecast confidence to stakeholders\n",
    "- **Continuous Monitoring**: Update models as new data becomes available\n",
    "\n",
    "### **Expert-Level Applications:**\n",
    "- **Multi-Series Forecasting**: Predict multiple related time series simultaneously\n",
    "- **External Variables**: Incorporate weather, holidays, economic indicators\n",
    "- **Real-Time Updates**: Build streaming analytics pipelines for live forecasting\n",
    "- **Hierarchical Forecasting**: Aggregate forecasts across product lines and regions\n",
    "\n",
    "---\n",
    "\n",
    "> **Complete Your Analytics Journey**: You've now mastered descriptive analytics, machine learning, and time series forecasting - the core pillars of data science!\n",
    "\n",
    "---\n",
    "\n",
    "*Excellent work completing the Time Series Analysis example! You're now equipped with professional forecasting skills essential for business analytics and strategic planning.*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}