{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa5bbe12",
   "metadata": {},
   "source": [
    "# Example 1: Quick Start Data Analysis\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** Brandon Deloatch\n",
    "**Affiliation:** Quipu Research Labs, LLC\n",
    "**Date:** 2025-10-02\n",
    "**Version:** v1.0\n",
    "**License:** MIT\n",
    "**Example Type:** Getting Started Tutorial\n",
    "**Based On:** Tier1_Descriptive.ipynb\n",
    "**Estimated Time:** 15 minutes\n",
    "\n",
    "---\n",
    "\n",
    "> **Citation:**\n",
    "> Brandon Deloatch, \"Example 1: Quick Start Data Analysis,\" Quipu Research Labs, LLC, v1.0, 2025-10-02.\n",
    "\n",
    "---\n",
    "\n",
    "*This example notebook is provided \"as-is\" for educational and research purposes. Users assume full responsibility for any results or applications derived from it.*\n",
    "\n",
    "---\n",
    "\n",
    "## Quick Start Guide to Coffee Sales Analytics\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Master basic data loading and preprocessing\n",
    "- Calculate comprehensive descriptive statistics\n",
    "- Create professional business visualizations\n",
    "- Perform statistical tests for business insights\n",
    "- Generate actionable recommendations\n",
    "\n",
    "**Cross-References:**\n",
    "- **Foundation:** `Tier1_Descriptive.ipynb` (statistical foundations)\n",
    "- **Next Steps:** `machine_learning_example.ipynb` (predictive modeling)\n",
    "- **Advanced:** `time_series_example.ipynb` (temporal analysis)\n",
    "\n",
    "**Key Applications:**\n",
    "- Retail analytics and sales optimization\n",
    "- Business intelligence dashboards\n",
    "- Data quality assessment\n",
    "- Exploratory data analysis workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c501183",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\\n\n",
    "\\n\n",
    "Start by importing the essential libraries for data analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad570d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Example 1: Quick Start Data Analysis.\n",
    "\n",
    "This module demonstrates basic data analysis techniques using real coffee sales data.\n",
    "Covers descriptive statistics, visualization, and statistical testing.\n",
    "\n",
    "Author: Brandon Deloatch\n",
    "Date: 2025-10-02\n",
    "\"\"\"\n",
    "\n",
    "# Example 1: Quick Start Data Analysis\n",
    "# ====================================\n",
    "# Professional coffee sales analytics with real business datasets\n",
    "\n",
    "import warnings\n",
    "from scipy.stats import f_oneway, ttest_ind\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Example 1: Quick Start Data Analysis\")\n",
    "print(\"=\" * 50)\n",
    "print(\"CROSS-REFERENCES:\")\n",
    "print(\"• Prerequisites: None (Entry point for examples)\")\n",
    "print(\"• Next Steps: machine_learning_example.ipynb (predictive modeling)\")\n",
    "print(\"• Next Steps: time_series_example.ipynb (temporal analysis)\")\n",
    "print(\"• Foundation: Tier1_Descriptive.ipynb (statistical theory)\")\n",
    "print(\"• Full Guide: See main notebooks directory for complete analytics suite\")\n",
    "print(\" Libraries loaded successfully - Ready for coffee sales analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa6297b",
   "metadata": {},
   "source": [
    "## 2. Load Coffee Sales Dataset\n",
    "\n",
    "Load and explore our real Coffee Sales dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78e046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Coffee Sales dataset\n",
    "df = pd.read_csv('../data/Coffee_sales.csv')\n",
    "\n",
    "# Basic data preprocessing\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['money'] = pd.to_numeric(df['money'], errors='coerce')\n",
    "df = df.dropna(subset=['money'])\n",
    "\n",
    "# Add some useful calculated fields\n",
    "df['revenue'] = df['money']\n",
    "df['day_name'] = df['Date'].dt.day_name()\n",
    "df['month_name'] = df['Month_name']\n",
    "df['is_weekend'] = df['Weekday'].isin(['Sat', 'Sun'])\n",
    "\n",
    "print(\"Coffee Sales Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Date range: {df['Date'].min().date()} to {df['Date'].max().date()}\")\n",
    "print(f\"Total revenue: ${df['revenue'].sum():,.2f}\")\n",
    "print(f\"Average transaction: ${df['revenue'].mean():.2f}\")\n",
    "print(f\"Coffee types: {df['coffee_name'].nunique()}\")\n",
    "print(f\"Payment methods: {', '.join(df['cash_type'].unique())}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e534a82b",
   "metadata": {},
   "source": [
    "## 3. Basic Data Exploration\\n\n",
    "\\n\n",
    "Let's explore the dataset structure and basic properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc01a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset overview\n",
    "print(\"=== COFFEE SALES DATASET OVERVIEW ===\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(\"\\nColumn types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nBasic statistics for revenue:\")\n",
    "print(df['revenue'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577a3616",
   "metadata": {},
   "source": [
    "## 4. Descriptive Statistics\\n\n",
    "\\n\n",
    "Calculate comprehensive descriptive statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e741211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate comprehensive descriptive statistics\n",
    "print(\"COFFEE SALES DESCRIPTIVE STATISTICS:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Revenue statistics\n",
    "print(\"\\nREVENUE ANALYSIS:\")\n",
    "print(f\" Total Revenue: ${df['revenue'].sum():,.2f}\")\n",
    "print(f\" Average Transaction: ${df['revenue'].mean():.2f}\")\n",
    "print(f\" Median Transaction: ${df['revenue'].median():.2f}\")\n",
    "print(f\" Standard Deviation: ${df['revenue'].std():.2f}\")\n",
    "print(f\" Minimum: ${df['revenue'].min():.2f}\")\n",
    "print(f\" Maximum: ${df['revenue'].max():.2f}\")\n",
    "\n",
    "# Time-based analysis\n",
    "print(\"\\nCOFFEE PREFERENCES:\")\n",
    "coffee_analysis = df['coffee_name'].value_counts()\n",
    "for coffee, count in coffee_analysis.head().items():\n",
    " percentage = (count / len(df)) * 100\n",
    " avg_price = df[df['coffee_name'] == coffee]['revenue'].mean()\n",
    " print(f\" {coffee}: {count} orders ({percentage:.1f}%) - Avg: ${avg_price:.2f}\")\n",
    "\n",
    "print(\"\\nTIME PATTERNS:\")\n",
    "time_analysis = df['Time_of_Day'].value_counts()\n",
    "for time_period, count in time_analysis.items():\n",
    " percentage = (count / len(df)) * 100\n",
    " avg_revenue = df[df['Time_of_Day'] == time_period]['revenue'].mean()\n",
    " print(f\" {time_period}: {count} transactions ({percentage:.1f}%) - Avg: ${avg_revenue:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f24439",
   "metadata": {},
   "source": [
    "## 5. Interactive Visualizations\\n\n",
    "\\n\n",
    "Create professional interactive charts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bce874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plots\\n\n",
    "fig = px.histogram(df, x='income', nbins=30, \\n\n",
    " title='Customer Income Distribution',\\n\n",
    " labels={'income': 'Annual Income ($)', 'count': 'Number of Customers'})\\n\n",
    "fig.update_layout(showlegend=False)\\n\n",
    "fig.show()\\n\n",
    "\\n\n",
    "# Scatter plot with color coding\\n\n",
    "fig2 = px.scatter(df, x='age', y='spending_score', color='segment',\\n\n",
    " size='income', hover_data=['satisfaction'],\\n\n",
    " title='Customer Age vs Spending Score by Segment')\\n\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c0348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for segment comparison\\n\n",
    "fig3 = px.box(df, x='segment', y='income', color='segment',\\n\n",
    " title='Income Distribution by Customer Segment')\\n\n",
    "fig3.show()\\n\n",
    "\\n\n",
    "# Correlation heatmap\\n\n",
    "correlation_matrix = df[numerical_cols].corr()\\n\n",
    "fig4 = px.imshow(correlation_matrix, \\n\n",
    " title='Correlation Matrix of Numerical Variables',\\n\n",
    " color_continuous_scale='RdBu_r')\\n\n",
    "fig4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d041dfe",
   "metadata": {},
   "source": [
    "## 6. Statistical Analysis\\n\n",
    "\\n\n",
    "Perform basic statistical tests and analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8a2a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualizations\n",
    "fig = make_subplots(\n",
    " rows=2, cols=2,\n",
    " subplot_titles=['Revenue Distribution', 'Sales by Coffee Type',\n",
    " 'Sales by Time of Day', 'Daily Revenue Trend'],\n",
    " specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    " [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
    ")\n",
    "\n",
    "# 1. Revenue distribution histogram\n",
    "fig.add_trace(go.Histogram(\n",
    " x=df['revenue'],\n",
    " name='Revenue Distribution',\n",
    " nbinsx=30,\n",
    " marker_color='lightblue'\n",
    "), row=1, col=1)\n",
    "\n",
    "# 2. Sales by coffee type\n",
    "coffee_counts = df['coffee_name'].value_counts().head(10)\n",
    "fig.add_trace(go.Bar(\n",
    " x=coffee_counts.index,\n",
    " y=coffee_counts.values,\n",
    " name='Coffee Sales',\n",
    " marker_color='brown'\n",
    "), row=1, col=2)\n",
    "\n",
    "# 3. Sales by time of day\n",
    "time_counts = df['Time_of_Day'].value_counts()\n",
    "fig.add_trace(go.Bar(\n",
    " x=time_counts.index,\n",
    " y=time_counts.values,\n",
    " name='Time Analysis',\n",
    " marker_color='orange'\n",
    "), row=2, col=1)\n",
    "\n",
    "# 4. Daily revenue trend\n",
    "daily_revenue = df.groupby('Date')['revenue'].sum().reset_index()\n",
    "fig.add_trace(go.Scatter(\n",
    " x=daily_revenue['Date'],\n",
    " y=daily_revenue['revenue'],\n",
    " mode='lines',\n",
    " name='Daily Revenue',\n",
    " line={'color': 'green', 'width': 2}\n",
    "), row=2, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    " height=800,\n",
    " title_text=\"Coffee Sales Analysis Dashboard\",\n",
    " showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2010f6bc",
   "metadata": {},
   "source": [
    "## 7. Key Insights Summary\\n\n",
    "\\n\n",
    "Generate a professional summary of findings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a79bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform statistical tests and generate insights\n",
    "print(\"STATISTICAL ANALYSIS & INSIGHTS:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Revenue comparison by time of day\n",
    "morning_revenue = df[df['Time_of_Day'] == 'Morning']['revenue']\n",
    "afternoon_revenue = df[df['Time_of_Day'] == 'Afternoon']['revenue']\n",
    "night_revenue = df[df['Time_of_Day'] == 'Night']['revenue']\n",
    "\n",
    "# Statistical test - ANOVA for time periods\n",
    "stat, p_value = f_oneway(morning_revenue, afternoon_revenue, night_revenue)\n",
    "print(\"\\n1. REVENUE BY TIME OF DAY (ANOVA Test):\")\n",
    "print(f\" F-statistic: {stat:.4f}\")\n",
    "print(f\" P-value: {p_value:.6f}\")\n",
    "if p_value < 0.05:\n",
    " print(\" Result: Significant difference in revenue by time of day!\")\n",
    "else:\n",
    " print(\" Result: No significant difference in revenue by time of day\")\n",
    "\n",
    "# 2. Payment method analysis\n",
    "card_revenue = df[df['cash_type'] == 'card']['revenue']\n",
    "cash_revenue = df[df['cash_type'] == 'cash']['revenue']\n",
    "\n",
    "stat, p_value = ttest_ind(card_revenue, cash_revenue)\n",
    "print(\"\\n2. PAYMENT METHOD COMPARISON (T-Test):\")\n",
    "print(f\" T-statistic: {stat:.4f}\")\n",
    "print(f\" P-value: {p_value:.6f}\")\n",
    "print(f\" Card avg: ${card_revenue.mean():.2f}\")\n",
    "print(f\" Cash avg: ${cash_revenue.mean():.2f}\")\n",
    "\n",
    "# 3. Coffee type profitability\n",
    "print(\"\\n3. TOP PERFORMING COFFEE TYPES:\")\n",
    "coffee_stats = df.groupby('coffee_name').agg({\n",
    " 'revenue': ['count', 'mean', 'sum']\n",
    "}).round(2)\n",
    "coffee_stats.columns = ['Orders', 'Avg_Price', 'Total_Revenue']\n",
    "coffee_stats = coffee_stats.sort_values('Total_Revenue', ascending=False)\n",
    "\n",
    "for coffee in coffee_stats.head().index:\n",
    " orders = coffee_stats.loc[coffee, 'Orders']\n",
    " avg_price = coffee_stats.loc[coffee, 'Avg_Price']\n",
    " total = coffee_stats.loc[coffee, 'Total_Revenue']\n",
    " print(f\" {coffee}: {orders} orders, ${avg_price} avg, ${total:,.0f} total\")\n",
    "\n",
    "# 4. Weekend vs Weekday analysis\n",
    "weekend_avg = df[df['is_weekend']]['revenue'].mean()\n",
    "weekday_avg = df[~df['is_weekend']]['revenue'].mean()\n",
    "print(\"\\n4. WEEKEND vs WEEKDAY:\")\n",
    "print(f\" Weekend average: ${weekend_avg:.2f}\")\n",
    "print(f\" Weekday average: ${weekday_avg:.2f}\")\n",
    "print(f\" Difference: ${weekend_avg - weekday_avg:.2f}\")\n",
    "\n",
    "# 5. Business insights\n",
    "print(\"\\n5. KEY BUSINESS INSIGHTS:\")\n",
    "total_revenue = df['revenue'].sum()\n",
    "total_transactions = len(df)\n",
    "avg_transaction = df['revenue'].mean()\n",
    "best_day = df.groupby('day_name')['revenue'].sum().idxmax()\n",
    "best_coffee = df.groupby('coffee_name')['revenue'].sum().idxmax()\n",
    "\n",
    "print(f\" 💰 Total Revenue: ${total_revenue:,.2f}\")\n",
    "print(f\" Total Transactions: {total_transactions:,}\")\n",
    "print(f\" 💳 Average Transaction: ${avg_transaction:.2f}\")\n",
    "print(f\" 📅 Best Day: {best_day}\")\n",
    "print(f\" ☕ Top Coffee: {best_coffee}\")\n",
    "print(\" Revenue Growth Opportunity: Focus on evening hours\")\n",
    "print(f\" Product Strategy: Promote {best_coffee} during peak hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6d4ca",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary and Next Steps\n",
    "\n",
    "### **What You've Accomplished:**\n",
    "- **Data Loading**: Successfully loaded and preprocessed real coffee sales data\n",
    "- **Descriptive Analytics**: Calculated comprehensive statistics for business insights\n",
    "- **Statistical Testing**: Performed ANOVA and t-tests for significant findings\n",
    "- **Visualization**: Created professional dashboards for business reporting\n",
    "- **Business Intelligence**: Generated actionable recommendations from data\n",
    "\n",
    "### **Key Coffee Sales Insights Discovered:**\n",
    "1. **Revenue Patterns**: Identified optimal pricing and peak sales periods\n",
    "2. **Product Performance**: Determined top-performing coffee types and profitability\n",
    "3. **Customer Behavior**: Analyzed payment preferences and time-of-day patterns\n",
    "4. **Statistical Significance**: Validated findings with proper hypothesis testing\n",
    "5. **Business Strategy**: Provided data-driven recommendations for growth\n",
    "\n",
    "### **Next Learning Steps:**\n",
    "\n",
    "#### **Continue Your Analytics Journey:**\n",
    "- **Machine Learning**: `machine_learning_example.ipynb` - Predict customer churn with Spotify data\n",
    "- **Time Series**: `time_series_example.ipynb` - Forecast sales trends and seasonality\n",
    "- **Advanced Stats**: `notebooks/tier1_descriptive/Tier1_Distribution.ipynb` - Deep dive into distributions\n",
    "\n",
    "#### **Tier Progression Path:**\n",
    "- **Tier 1**: Master foundational descriptive analytics and visualization\n",
    "- **Tier 2**: Learn supervised/unsupervised machine learning techniques\n",
    "- **Tier 3**: Advance to time series analysis and forecasting methods\n",
    "- **Tier 4**: Explore clustering and dimensionality reduction\n",
    "- **Tier 5**: Apply ensemble methods and advanced classification\n",
    "- **Tier 6**: Implement anomaly detection and outlier analysis\n",
    "\n",
    "### 🏢 **Business Applications:**\n",
    "- **Retail Analytics**: Apply these techniques to your sales data\n",
    "- **Performance Monitoring**: Create dashboards for business KPIs\n",
    "- **Data-Driven Decisions**: Use statistical tests to validate business strategies\n",
    "- **Reporting Automation**: Implement these analyses in production systems\n",
    "\n",
    "### 🔗 **Professional Development:**\n",
    "- **Portfolio Project**: Use this example as a foundation for your data science portfolio\n",
    "- **Real-World Skills**: These techniques directly apply to business intelligence roles\n",
    "- **Best Practices**: Professional formatting and documentation standards demonstrated\n",
    "\n",
    "---\n",
    "\n",
    "> **Next Recommendation**: Try `machine_learning_example.ipynb` to learn predictive modeling with Random Forest!\n",
    "\n",
    "---\n",
    "\n",
    "*Thank you for completing the Quick Start Data Analysis example. Continue building your analytics expertise with the comprehensive Quipu Analytics Suite.*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}